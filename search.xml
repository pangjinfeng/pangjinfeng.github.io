<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Linux unzip 命令]]></title>
    <url>%2F2019%2F03%2F28%2FLinux-unzip-%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux unzip命令用于解压缩zip文件unzip为.zip压缩文件的解压缩程序。 语法1unzip [-cflptuvz][-agCjLMnoqsVX][-P &lt;密码&gt;][.zip文件][文件][-d &lt;目录&gt;][-x &lt;文件&gt;] 或 unzip [-Z] 参数 -c 将解压缩的结果显示到屏幕上，并对字符做适当的转换。 -f 更新现有的文件。 -l 显示压缩文件内所包含的文件。 -p 与-c参数类似，会将解压缩的结果显示到屏幕上，但不会执行任何的转换。 -t 检查压缩文件是否正确。 -u 与-f参数类似，但是除了更新现有的文件外，也会将压缩文件中的其他文件解压缩到目录中。 -v 执行是时显示详细的信息。 -z 仅显示压缩文件的备注文字。 -a 对文本文件进行必要的字符转换。 -b 不要对文本文件进行字符转换。 -C 压缩文件中的文件名称区分大小写。 -j 不处理压缩文件中原有的目录路径。 -L 将压缩文件中的全部文件名改为小写。 -M 将输出结果送到more程序处理。 -n 解压缩时不要覆盖原有的文件。 -o 不必先询问用户，unzip执行后覆盖原有文件。 -P&lt;密码&gt; 使用zip的密码选项。 -q 执行时不显示任何信息。 -s 将文件名中的空白字符转换为底线字符。 -V 保留VMS的文件版本信息。 -X 解压缩时同时回存文件原来的UID/GID。 [.zip文件] 指定.zip压缩文件。 [文件] 指定要处理.zip压缩文件中的哪些文件。 -d&lt;目录&gt; 指定文件解压缩后所要存储的目录。 -x&lt;文件&gt; 指定不要处理.zip压缩文件中的哪些文件。 -Z unzip -Z等于执行zipinfo指令。 实例查看压缩文件中包含的文件：1234567891011# unzip -l abc.zip Archive: abc.zip Length Date Time Name-------- ---- ---- ---- 94618 05-21-10 20:44 a11.jpg 202001 05-21-10 20:44 a22.jpg 16 05-22-10 15:01 11.txt 46468 05-23-10 10:30 w456.JPG 140085 03-14-10 21:49 my.asp-------- ------- 483188 5 files -v 参数用于查看压缩文件目录信息，但是不解压该文件。12345678910Archive: abc.zipLength Method Size Ratio Date Time CRC-32 Name-------- ------ ------- ----- ---- ---- ------ ---- 94618 Defl:N 93353 1% 05-21-10 20:44 9e661437 a11.jpg 202001 Defl:N 201833 0% 05-21-10 20:44 1da462eb a22.jpg 16 Stored 16 0% 05-22-10 15:01 ae8a9910 ? +-|￥+-? (11).txt 46468 Defl:N 39997 14% 05-23-10 10:30 962861f2 w456.JPG 140085 Defl:N 36765 74% 03-14-10 21:49 836fcc3f my.asp-------- ------- --- ------- 483188 371964 23% 5 files]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux zip 命令]]></title>
    <url>%2F2019%2F03%2F28%2FLinux-zip-%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux zip命令用于压缩文件。zip是个使用广泛的压缩程序，文件经它压缩后会另外产生具有”.zip”扩展名的压缩文件。 语法1zip [-AcdDfFghjJKlLmoqrSTuvVwXyz$][-b &lt;工作目录&gt;][-ll][-n &lt;字尾字符串&gt;][-t &lt;日期时间&gt;][-&lt;压缩效率&gt;][压缩文件][文件...][-i &lt;范本样式&gt;][-x &lt;范本样式&gt;] 参数 -A 调整可执行的自动解压缩文件。 -b&lt;工作目录&gt; 指定暂时存放文件的目录。 -c 替每个被压缩的文件加上注释。 -d 从压缩文件内删除指定的文件。 -D 压缩文件内不建立目录名称。 -f 此参数的效果和指定”-u”参数类似，但不仅更新既有文件，如果某些文件原本不存在于压缩文件内，使用本参数会一并将其加入压缩文件中。 -F 尝试修复已损坏的压缩文件。 -g 将文件压缩后附加在既有的压缩文件之后，而非另行建立新的压缩文件。 -h 在线帮助。 -i&lt;范本样式&gt; 只压缩符合条件的文件。 -j 只保存文件名称及其内容，而不存放任何目录名称。 -J 删除压缩文件前面不必要的数据。 -k 使用MS-DOS兼容格式的文件名称。 -l 压缩文件时，把LF字符置换成LF+CR字符。 -ll 压缩文件时，把LF+CR字符置换成LF字符。 -L 显示版权信息。 -m 将文件压缩并加入压缩文件后，删除原始文件，即把文件移到压缩文件中。 -n&lt;字尾字符串&gt; 不压缩具有特定字尾字符串的文件。 -o 以压缩文件内拥有最新更改时间的文件为准，将压缩文件的更改时间设成和该文件相同。 -q 不显示指令执行过程。 -r 递归处理，将指定目录下的所有文件和子目录一并处理。 -S 包含系统和隐藏文件。 -t&lt;日期时间&gt; 把压缩文件的日期设成指定的日期。 -T 检查备份文件内的每个文件是否正确无误。 -u 更换较新的文件到压缩文件内。 -v 显示指令执行过程或显示版本信息。 -V 保存VMS操作系统的文件属性。 -w 在文件名称里假如版本编号，本参数仅在VMS操作系统下有效。 -x&lt;范本样式&gt; 压缩时排除符合条件的文件。 -X 不保存额外的文件属性。 -y 直接保存符号连接，而非该连接所指向的文件，本参数仅在UNIX之类的系统下有效。 -z 替压缩文件加上注释。 -$ 保存第一个被压缩文件所在磁盘的卷册名称。 -&lt;压缩效率&gt; 压缩效率是一个介于1-9的数值。 实例将 /home/html/ 这个目录下所有文件和文件夹打包为当前目录下的 html.zip：1zip -q -r html.zip /home/html 如果在我们在 /home/html 目录下，可以执行以下命令：1zip -q -r html.zip * 从压缩文件 cp.zip 中删除文件 a.c 1zip -dv cp.zip a.c]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux tar 命令]]></title>
    <url>%2F2019%2F03%2F28%2FLinux-tar-%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux tar命令用于备份文件。tar是用来建立，还原备份文件的工具程序，它可以加入，解开备份文件内的文件。 语法1tar [-ABcdgGhiklmMoOpPrRsStuUvwWxzZ][-b &lt;区块数目&gt;][-C &lt;目的目录&gt;][-f &lt;备份文件&gt;][-F &lt;Script文件&gt;][-K &lt;文件&gt;][-L &lt;媒体容量&gt;][-N &lt;日期时间&gt;][-T &lt;范本文件&gt;][-V &lt;卷册名称&gt;][-X &lt;范本文件&gt;][-&lt;设备编号&gt;&lt;存储密度&gt;][--after-date=&lt;日期时间&gt;][--atime-preserve][--backuup=&lt;备份方式&gt;][--checkpoint][--concatenate][--confirmation][--delete][--exclude=&lt;范本样式&gt;][--force-local][--group=&lt;群组名称&gt;][--help][--ignore-failed-read][--new-volume-script=&lt;Script文件&gt;][--newer-mtime][--no-recursion][--null][--numeric-owner][--owner=&lt;用户名称&gt;][--posix][--erve][--preserve-order][--preserve-permissions][--record-size=&lt;区块数目&gt;][--recursive-unlink][--remove-files][--rsh-command=&lt;执行指令&gt;][--same-owner][--suffix=&lt;备份字尾字符串&gt;][--totals][--use-compress-program=&lt;执行指令&gt;][--version][--volno-file=&lt;编号文件&gt;][文件或目录...] 参数 -A或–catenate 新增文件到已存在的备份文件。 -b&lt;区块数目&gt;或–blocking-factor=&lt;区块数目&gt; 设置每笔记录的区块数目，每个区块大小为12Bytes。 -B或–read-full-records 读取数据时重设区块大小。 -c或–create 建立新的备份文件。 -C&lt;目的目录&gt;或–directory=&lt;目的目录&gt; 切换到指定的目录。 -d或–diff或–compare 对比备份文件内和文件系统上的文件的差异。 -f&lt;备份文件&gt;或–file=&lt;备份文件&gt; 指定备份文件。 -F&lt;Script文件&gt;或–info-script=&lt;Script文件&gt; 每次更换磁带时，就执行指定的Script文件。 -g或–listed-incremental 处理GNU格式的大量备份。 -G或–incremental 处理旧的GNU格式的大量备份。 -h或–dereference 不建立符号连接，直接复制该连接所指向的原始文件。 -i或–ignore-zeros 忽略备份文件中的0 Byte区块，也就是EOF。 -k或–keep-old-files 解开备份文件时，不覆盖已有的文件。 -K&lt;文件&gt;或–starting-file=&lt;文件&gt; 从指定的文件开始还原。 -l或–one-file-system 复制的文件或目录存放的文件系统，必须与tar指令执行时所处的文件系统相同，否则不予复制。 -L&lt;媒体容量&gt;或-tape-length=&lt;媒体容量&gt; 设置存放每体的容量，单位以1024 Bytes计算。 -m或–modification-time 还原文件时，不变更文件的更改时间。 -M或–multi-volume 在建立，还原备份文件或列出其中的内容时，采用多卷册模式。 -N&lt;日期格式&gt;或–newer=&lt;日期时间&gt; 只将较指定日期更新的文件保存到备份文件里。 -o或–old-archive或–portability 将资料写入备份文件时使用V7格式。 -O或–stdout 把从备份文件里还原的文件输出到标准输出设备。 -p或–same-permissions 用原来的文件权限还原文件。 -P或–absolute-names 文件名使用绝对名称，不移除文件名称前的”/“号。 -r或–append 新增文件到已存在的备份文件的结尾部分。 -R或–block-number 列出每个信息在备份文件中的区块编号。 -s或–same-order 还原文件的顺序和备份文件内的存放顺序相同。 -S或–sparse 倘若一个文件内含大量的连续0字节，则将此文件存成稀疏文件。 -t或–list 列出备份文件的内容。 -T&lt;范本文件&gt;或–files-from=&lt;范本文件&gt; 指定范本文件，其内含有一个或多个范本样式，让tar解开或建立符合设置条件的文件。 -u或–update 仅置换较备份文件内的文件更新的文件。 -U或–unlink-first 解开压缩文件还原文件之前，先解除文件的连接。 -v或–verbose 显示指令执行过程。 -V&lt;卷册名称&gt;或–label=&lt;卷册名称&gt; 建立使用指定的卷册名称的备份文件。 -w或–interactive 遭遇问题时先询问用户。 -W或–verify 写入备份文件后，确认文件正确无误。 -x或–extract或–get 从备份文件中还原文件。 -X&lt;范本文件&gt;或–exclude-from=&lt;范本文件&gt; 指定范本文件，其内含有一个或多个范本样式，让ar排除符合设置条件的文件。 -z或–gzip或–ungzip 通过gzip指令处理备份文件。 -Z或–compress或–uncompress 通过compress指令处理备份文件。 -&lt;设备编号&gt;&lt;存储密度&gt; 设置备份用的外围设备编号及存放数据的密度。 –after-date=&lt;日期时间&gt; 此参数的效果和指定”-N”参数相同。 –atime-preserve 不变更文件的存取时间。 –backup=&lt;备份方式&gt;或–backup 移除文件前先进行备份。 –checkpoint 读取备份文件时列出目录名称。 –concatenate 此参数的效果和指定”-A”参数相同。 –confirmation 此参数的效果和指定”-w”参数相同。 –delete 从备份文件中删除指定的文件。 –exclude=&lt;范本样式&gt; 排除符合范本样式的问家。 –group=&lt;群组名称&gt; 把加入设备文件中的文件的所属群组设成指定的群组。 –help 在线帮助。 –ignore-failed-read 忽略数据读取错误，不中断程序的执行。 –new-volume-script=&lt;Script文件&gt; 此参数的效果和指定”-F”参数相同。 –newer-mtime 只保存更改过的文件。 –no-recursion 不做递归处理，也就是指定目录下的所有文件及子目录不予处理。 –null 从null设备读取文件名称。 –numeric-owner 以用户识别码及群组识别码取代用户名称和群组名称。 –owner=&lt;用户名称&gt; 把加入备份文件中的文件的拥有者设成指定的用户。 –posix 将数据写入备份文件时使用POSIX格式。 –preserve 此参数的效果和指定”-ps”参数相同。 –preserve-order 此参数的效果和指定”-A”参数相同。 –preserve-permissions 此参数的效果和指定”-p”参数相同。 –record-size=&lt;区块数目&gt; 此参数的效果和指定”-b”参数相同。 –recursive-unlink 解开压缩文件还原目录之前，先解除整个目录下所有文件的连接。 –remove-files 文件加入备份文件后，就将其删除。 –rsh-command=&lt;执行指令&gt; 设置要在远端主机上执行的指令，以取代rsh指令。 –same-owner 尝试以相同的文件拥有者还原文件。 –suffix=&lt;备份字尾字符串&gt; 移除文件前先行备份。 –totals 备份文件建立后，列出文件大小。 –use-compress-program=&lt;执行指令&gt; 通过指定的指令处理备份文件。 –version 显示版本信息。 –volno-file=&lt;编号文件&gt; 使用指定文件内的编号取代预设的卷册编号。 实例压缩文件 非打包123# touch a.c # tar -czvf test.tar.gz a.c //压缩 a.c文件为test.tar.gza.c 列出压缩文件内容12# tar -tzvf test.tar.gz -rw-r--r-- root/root 0 2010-05-24 16:51:59 a.c 解压文件12# tar -xzvf test.tar.gz a.c]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux gunzip 命令]]></title>
    <url>%2F2019%2F03%2F28%2FLinux-gunzip-%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux gunzip命令用于解压文件。gunzip是个使用广泛的解压缩程序，它用于解开被gzip压缩过的文件，这些压缩文件预设最后的扩展名为”.gz”。事实上gunzip就是gzip的硬连接，因此不论是压缩或解压缩，都可通过gzip指令单独完成。 语法1gunzip [-acfhlLnNqrtvV][-s &lt;压缩字尾字符串&gt;][文件...] 或 gunzip [-acfhlLnNqrtvV][-s &lt;压缩字尾字符串&gt;][目录] 参数 -a或–ascii 使用ASCII文字模式。 -c或–stdout或–to-stdout 把解压后的文件输出到标准输出设备。 -f或-force 强行解开压缩文件，不理会文件名称或硬连接是否存在以及该文件是否为符号连接。 -h或–help 在线帮助。 -l或–list 列出压缩文件的相关信息。 -L或–license 显示版本与版权信息。 -n或–no-name 解压缩时，若压缩文件内含有远来的文件名称及时间戳记，则将其忽略不予处理。 -N或–name 解压缩时，若压缩文件内含有原来的文件名称及时间戳记，则将其回存到解开的文件上。 -q或–quiet 不显示警告信息。 -r或–recursive 递归处理，将指定目录下的所有文件及子目录一并处理。 -S&lt;压缩字尾字符串&gt;或–suffix&lt;压缩字尾字符串&gt; 更改压缩字尾字符串。 -t或–test 测试压缩文件是否正确无误。 -v或–verbose 显示指令执行过程。 -V或–version 显示版本信息。 实例1234&lt;p&gt;解压文件&lt;/p&gt;&lt;pre&gt;# gunzip ab.gz]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux bzip2recover 命令]]></title>
    <url>%2F2019%2F03%2F28%2FLinux-bzip2recover-%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux bzip2recover命令用来修复损坏的.bz2文件。bzip2是以区块的方式来压缩文件，每个区块视为独立的单位。因此，当某一区块损坏时，便可利用bzip2recover，试着将文件中的区块隔开来，以便解压缩正常的区块。通常只适用在压缩文件很大的情况。 语法1bzip2recover [.bz2 压缩文件] 实例修复.bz2文件1# bzip2recover col.bz2]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux bzip2 命令]]></title>
    <url>%2F2019%2F03%2F28%2FLinux-bzip2-%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux bzip2命令是.bz2文件的压缩程序。bzip2采用新的压缩演算法，压缩效果比传统的LZ77/LZ78压缩演算法来得好。若没有加上任何参数，bzip2压缩完文件后会产生.bz2的压缩文件，并删除原始的文件。 语法1bzip2 [-cdfhkLstvVz][--repetitive-best][--repetitive-fast][- 压缩等级][要压缩的文件] 参数 -c或–stdout 将压缩与解压缩的结果送到标准输出。 -d或–decompress 执行解压缩。 -f或–force bzip2在压缩或解压缩时，若输出文件与现有文件同名，预设不会覆盖现有文件。若要覆盖，请使用此参数。 -h或–help 显示帮助。 -k或–keep bzip2在压缩或解压缩后，会删除原始的文件。若要保留原始文件，请使用此参数。 -s或–small 降低程序执行时内存的使用量。 -t或–test 测试.bz2压缩文件的完整性。 -v或–verbose 压缩或解压缩文件时，显示详细的信息。 -z或–compress 强制执行压缩。 -L,–license, -V或–version 显示版本信息。 –repetitive-best 若文件中有重复出现的资料时，可利用此参数提高压缩效果。 –repetitive-fast 若文件中有重复出现的资料时，可利用此参数加快执行速度。 -压缩等级 压缩时的区块大小。实例解压.bz2文件1[root@w3cschool.cc ~]# bzip2 -v temp.bz2 //解压文件显示详细处理信息 压缩文件1[root@w3cschool.cc ~]# bzip2 -c a.c b.c c.c 检查文件完整性1[root@w3cschool.cc ~]# bzip2 -t temp.bz2]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux pwd 命令]]></title>
    <url>%2F2019%2F03%2F28%2FLinux-pwd-%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux pwd命令用于显示工作目录。执行pwd指令可立刻得知您目前所在的工作目录的绝对路径名称。 语法1pwd [--help][--version] 参数说明 –help 在线帮助。 –version 显示版本信息。实例查看当前所在目录：12# pwd/root/test #输出结果]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux df 命令]]></title>
    <url>%2F2019%2F03%2F27%2FLinux-df-%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux df命令用于显示目前在Linux系统上的文件系统的磁盘使用情况统计。 语法1df [选项]... [FILE]... 参数 -a, –all 包含所有的具有 0 Blocks 的文件系统 –block-size={SIZE} 使用 {SIZE} 大小的 Blocks -h, –human-readable 使用人类可读的格式(预设值是不加这个选项的…) -H, –si 很像 -h, 但是用 1000 为单位而不是用 1024 -i, –inodes 列出 inode 资讯，不列出已使用 block -k, –kilobytes 就像是 –block-size=1024 -l, –local 限制列出的文件结构 -m, –megabytes 就像 –block-size=1048576 –no-sync 取得资讯前不 sync (预设值) -P, –portability 使用 POSIX 输出格式 –sync 在取得资讯前 sync -t, –type=TYPE 限制列出文件系统的 TYPE -T, –print-type 显示文件系统的形式 -x, –exclude-type=TYPE 限制列出文件系统不要显示 TYPE -v (忽略) –help 显示这个帮手并且离开 –version 输出版本资讯并且离开 实例显示文件系统的磁盘使用情况统计：1234567# df Filesystem 1K-blocks Used Available Use% Mounted on /dev/sda6 29640780 4320704 23814388 16% / udev 1536756 4 1536752 1% /dev tmpfs 617620 888 616732 1% /run none 5120 0 5120 0% /run/lock none 1544044 156 1543888 1% /run/shm 第一列指定文件系统的名称，第二列指定一个特定的文件系统1K-块1K是1024字节为单位的总内存。用和可用列正在使用中，分别指定的内存量。 使用列指定使用的内存的百分比，而最后一栏”安装在”指定的文件系统的挂载点。 df也可以显示磁盘使用的文件系统信息：123# df test Filesystem 1K-blocks Used Available Use% Mounted on /dev/sda6 29640780 4320600 23814492 16% / 用一个-i选项的df命令的输出显示inode信息而非块使用量。1234567df -i Filesystem Inodes IUsed IFree IUse% Mounted on /dev/sda6 1884160 261964 1622196 14% / udev 212748 560 212188 1% /dev tmpfs 216392 477 215915 1% /run none 216392 3 216389 1% /run/lock none 216392 8 216384 1% /run/shm 显示所有的信息:12345678# df --total Filesystem 1K-blocks Used Available Use% Mounted on /dev/sda6 29640780 4320720 23814372 16% / udev 1536756 4 1536752 1% /dev tmpfs 617620 892 616728 1% /run none 5120 0 5120 0% /run/lock none 1544044 156 1543888 1% /run/shm total 33344320 4321772 27516860 14% 我们看到输出的末尾，包含一个额外的行，显示总的每一列。 -h选项，通过它可以产生可读的格式df命令的输出：1234567# df -h Filesystem Size Used Avail Use% Mounted on /dev/sda6 29G 4.2G 23G 16% / udev 1.5G 4.0K 1.5G 1% /dev tmpfs 604M 892K 603M 1% /run none 5.0M 0 5.0M 0% /run/lock none 1.5G 156K 1.5G 1% /run/shm 我们可以看到输出显示的数字形式的’G’（千兆字节），”M”（兆字节）和”K”（千字节）。 这使输出容易阅读和理解，从而使显示可读的。请注意，第二列的名称也发生了变化，为了使显示可读的”大小”。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UntitledLinux mdir 命令]]></title>
    <url>%2F2019%2F03%2F27%2FUntitledLinux-mdir-%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux mdir命令用于显示MS-DOS目录。mdir为mtools工具指令，模拟MS-DOS的dir指令，可显示MS-DOS文件系统中的目录内容。 语法1mdir [-afwx/][目录] 参数 -/ 显示目录下所有子目录与文件。 -a 显示隐藏文件。 -f 不显示磁盘所剩余的可用空间。 -w 仅显示目录或文件名称，并以横排方式呈现，以便一次能显示较多的目录或文件。 -X 仅显示目录下所有子目录与文件的完整路径，不显示其他信息。 实例显示a盘中的内容1$ mdir -/ a:\* 以上命令执行后，mdir将显示指定盘”a:\”中的所有子目录及其中的文件信息，如下所示：123456789Volume in drive A has no label #加载信息 Volume Serial Number is 13D2~055C Directory for A:\ #以下为目录信息 ./TEST &lt;DIR&gt; 2011-08-23 16:59 #显示格式为文件名，目录大小，修改时间 AUTORUN.INF 265 2011-08-23 16:53 AUTORUN.BAT 43 2011-08-23 16:56 3 files 308 bytes #统计总大小 724 325 bytes free #剩余空间]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux awk 命令]]></title>
    <url>%2F2019%2F03%2F26%2FLinux-awk-%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[AWK是一种处理文本文件的语言，是一个强大的文本分析工具。之所以叫AWK是因为其取了三位创始人 Alfred Aho，Peter Weinberger, 和 Brian Kernighan 的 Family Name 的首字符。 语法123awk [选项参数] &apos;script&apos; var=value file(s)或awk [选项参数] -f scriptfile var=value file(s) 参数 -F fs or –field-separator fs指定输入文件折分隔符，fs是一个字符串或者是一个正则表达式，如-F:。 -v var=value or –asign var=value赋值一个用户定义变量。 -f scripfile or –file scriptfile从脚本文件中读取awk命令。 -mf nnn and -mr nnn对nnn值设置内在限制，-mf选项限制分配给nnn的最大块数目；-mr选项限制记录的最大数目。这两个功能是Bell实验室版awk的扩展功能，在标准awk中不适用。 -W compact or –compat, -W traditional or –traditional在兼容模式下运行awk。所以gawk的行为和标准的awk完全一样，所有的awk扩展都被忽略。 -W copyleft or –copyleft, -W copyright or –copyright打印简短的版权信息。 -W help or –help, -W usage or –usage打印全部awk选项和每个选项的简短说明。 -W lint or –lint打印不能向传统unix平台移植的结构的警告。 -W lint-old or –lint-old打印关于不能向传统unix平台移植的结构的警告。 -W posix打开兼容模式。但有以下限制，不识别：/x、函数关键字、func、换码序列以及当fs是一个空格时，将新行作为一个域分隔符；操作符和=不能代替^和^=；fflush无效。 -W re-interval or –re-inerval允许间隔正则表达式的使用，参考(grep中的Posix字符类)，如括号表达式[[:alpha:]]。 -W source program-text or –source program-text使用program-text作为源代码，可与-f命令混用。 -W version or –version打印bug报告信息的版本。 基本用法log.txt文本内容如下：12342 this is a test3 Are you like awkThis&apos;s a test10 There are orange,apple,mongo 用法一： 1awk &apos;&#123;[pattern] action&#125;&apos; &#123;filenames&#125; # 行匹配语句 awk &apos;&apos; 只能用单引号 实例:1234567891011121314# 每行按空格或TAB分割，输出文本中的1、4项 $ awk &apos;&#123;print $1,$4&#125;&apos; log.txt --------------------------------------------- 2 a 3 like This&apos;s 10 orange,apple,mongo # 格式化输出 $ awk &apos;&#123;printf &quot;%-8s %-10s\n&quot;,$1,$4&#125;&apos; log.txt --------------------------------------------- 2 a 3 like This&apos;s 10 orange,apple,mongo 用法二：1awk -F #-F相当于内置变量FS, 指定分割字符 实例：123456789101112131415161718192021# 使用&quot;,&quot;分割 $ awk -F, &apos;&#123;print $1,$2&#125;&apos; log.txt --------------------------------------------- 2 this is a test 3 Are you like awk This&apos;s a test 10 There are orange apple # 或者使用内建变量 $ awk &apos;BEGIN&#123;FS=&quot;,&quot;&#125; &#123;print $1,$2&#125;&apos; log.txt --------------------------------------------- 2 this is a test 3 Are you like awk This&apos;s a test 10 There are orange apple # 使用多个分隔符.先使用空格分割，然后对分割结果再使用&quot;,&quot;分割 $ awk -F &apos;[ ,]&apos; &apos;&#123;print $1,$2,$5&#125;&apos; log.txt --------------------------------------------- 2 this test 3 Are awk This&apos;s a 10 There apple 用法三：1awk -v # 设置变量 实例：123456789101112$ awk -va=1 &apos;&#123;print $1,$1+a&#125;&apos; log.txt---------------------------------------------2 33 4This&apos;s 110 11$ awk -va=1 -vb=s &apos;&#123;print $1,$1+a,$1b&#125;&apos; log.txt---------------------------------------------2 3 2s3 4 3sThis&apos;s 1 This&apos;ss10 11 10s 用法四：1awk -f &#123;awk脚本&#125; &#123;文件名&#125; 实例：1$ awk -f cal.awk log.txt 运算符 运算符 描述 = += -= *= /= %= ^= **= 赋值 ?: C条件表达式 11 逻辑或 &amp;&amp; 逻辑与 ~ ~! 匹配正则表达式和不匹配正则表达式 &lt; &lt;= &gt; &gt;= != == 关系运算符 空格 连接 + - 加，减 * / % 乘，除与求余 + - ! 一元加，减和逻辑非 ^ *** 求幂 ++ – 增加或减少，作为前缀或后缀 $ 字段引用 in 数组成员 其中11为ll过滤第一列大于2的行12345$ awk &apos;$1&gt;2&apos; log.txt #命令#输出3 Are you like awkThis&apos;s a test10 There are orange,apple,mongo 过滤第一列等于2的行123$ awk &apos;$1==2 &#123;print $1,$3&#125;&apos; log.txt #命令#输出2 is 过滤第一列大于2并且第二列等于’Are’的行123$ awk &apos;$1&gt;2 &amp;&amp; $2==&quot;Are&quot; &#123;print $1,$2,$3&#125;&apos; log.txt #命令#输出3 Are you 内建变量 变量 描述 $n 当前记录的第n个字段，字段间由FS分隔 $0 完整的输入记录 ARGC 命令行参数的数目 ARGIND 命令行中当前文件的位置(从0开始算) ARGV 包含命令行参数的数组 CONVFMT 数字转换格式(默认值为%.6g)ENVIRON环境变量关联数组 ERRNO 最后一个系统错误的描述 FIELDWIDTHS 字段宽度列表(用空格键分隔) FILENAME 当前文件名 FNR 各文件分别计数的行号 FS 字段分隔符(默认是任何空格) IGNORECASE 如果为真，则进行忽略大小写的匹配 NF 一条记录的字段的数目 NR 已经读出的记录数，就是行号，从1开始 OFMT 数字的输出格式(默认值是%.6g) OFS 输出记录分隔符（输出换行符），输出时用指定的符号代替换行符 ORS 输出记录分隔符(默认值是一个换行符) RLENGTH 由match函数所匹配的字符串的长度 RS 记录分隔符(默认是一个换行符) RSTART 由match函数所匹配的字符串的第一个位置 SUBSEP 数组下标分隔符(默认值是/034) 12345678910111213141516171819202122232425262728$ awk &apos;BEGIN&#123;printf &quot;%4s %4s %4s %4s %4s %4s %4s %4s %4s\n&quot;,&quot;FILENAME&quot;,&quot;ARGC&quot;,&quot;FNR&quot;,&quot;FS&quot;,&quot;NF&quot;,&quot;NR&quot;,&quot;OFS&quot;,&quot;ORS&quot;,&quot;RS&quot;;printf &quot;---------------------------------------------\n&quot;&#125; &#123;printf &quot;%4s %4s %4s %4s %4s %4s %4s %4s %4s\n&quot;,FILENAME,ARGC,FNR,FS,NF,NR,OFS,ORS,RS&#125;&apos; log.txtFILENAME ARGC FNR FS NF NR OFS ORS RS---------------------------------------------log.txt 2 1 5 1log.txt 2 2 5 2log.txt 2 3 3 3log.txt 2 4 4 4$ awk -F\&apos; &apos;BEGIN&#123;printf &quot;%4s %4s %4s %4s %4s %4s %4s %4s %4s\n&quot;,&quot;FILENAME&quot;,&quot;ARGC&quot;,&quot;FNR&quot;,&quot;FS&quot;,&quot;NF&quot;,&quot;NR&quot;,&quot;OFS&quot;,&quot;ORS&quot;,&quot;RS&quot;;printf &quot;---------------------------------------------\n&quot;&#125; &#123;printf &quot;%4s %4s %4s %4s %4s %4s %4s %4s %4s\n&quot;,FILENAME,ARGC,FNR,FS,NF,NR,OFS,ORS,RS&#125;&apos; log.txtFILENAME ARGC FNR FS NF NR OFS ORS RS---------------------------------------------log.txt 2 1 &apos; 1 1log.txt 2 2 &apos; 1 2log.txt 2 3 &apos; 2 3log.txt 2 4 &apos; 1 4# 输出顺序号 NR, 匹配文本行号$ awk &apos;&#123;print NR,FNR,$1,$2,$3&#125;&apos; log.txt---------------------------------------------1 1 2 this is2 2 3 Are you3 3 This&apos;s a test4 4 10 There are# 指定输出分割符$ awk &apos;&#123;print $1,$2,$5&#125;&apos; OFS=&quot; $ &quot; log.txt---------------------------------------------2 $ this $ test3 $ Are $ awkThis&apos;s $ a $10 $ There $ 使用正则，字符串匹配1234# 输出第二列包含 &quot;th&quot;，并打印第二列与第四列$ awk &apos;$2 ~ /th/ &#123;print $2,$4&#125;&apos; log.txt---------------------------------------------this a ~ 表示模式开始。// 中是模式。12345# 输出包含&quot;re&quot; 的行$ awk &apos;/re/ &apos; log.txt---------------------------------------------3 Are you like awk10 There are orange,apple,mongo 忽略大小写1234$ awk &apos;BEGIN&#123;IGNORECASE=1&#125; /this/&apos; log.txt---------------------------------------------2 this is a testThis&apos;s a test 模式取反12345678910$ awk &apos;$2 !~ /th/ &#123;print $2,$4&#125;&apos; log.txt---------------------------------------------Are likeaThere orange,apple,mongo$ awk &apos;!/th/ &#123;print $2,$4&#125;&apos; log.txt---------------------------------------------Are likeaThere orange,apple,mongo awk脚本关于awk脚本，我们需要注意两个关键词BEGIN和END。 BEGIN{ 这里面放的是执行前的语句 } END {这里面放的是处理完所有的行后要执行的语句 } {这里面放的是处理每一行时要执行的语句}假设有这么一个文件（学生成绩表）： 123456$ cat score.txtMarry 2143 78 84 77Jack 2321 66 78 45Tom 2122 48 77 71Mike 2537 87 97 95Bob 2415 40 57 62 我们的awk脚本如下：123456789101112131415161718192021222324$ cat cal.awk#!/bin/awk -f#运行前BEGIN &#123; math = 0 english = 0 computer = 0 printf &quot;NAME NO. MATH ENGLISH COMPUTER TOTAL\n&quot; printf &quot;---------------------------------------------\n&quot;&#125;#运行中&#123; math+=$3 english+=$4 computer+=$5 printf &quot;%-6s %-6s %4d %8d %8d %8d\n&quot;, $1, $2, $3,$4,$5, $3+$4+$5&#125;#运行后END &#123; printf &quot;---------------------------------------------\n&quot; printf &quot; TOTAL:%10d %8d %8d \n&quot;, math, english, computer printf &quot;AVERAGE:%10.2f %8.2f %8.2f\n&quot;, math/NR, english/NR, computer/NR&#125; 我们来看一下执行结果： 1234567891011$ awk -f cal.awk score.txtNAME NO. MATH ENGLISH COMPUTER TOTAL---------------------------------------------Marry 2143 78 84 77 239Jack 2321 66 78 45 189Tom 2122 48 77 71 196Mike 2537 87 97 95 279Bob 2415 40 57 62 159--------------------------------------------- TOTAL: 319 393 350AVERAGE: 63.80 78.60 70.00 另外一些实例AWK的hello world程序为：1BEGIN &#123; print &quot;Hello, world!&quot; &#125; 计算文件大小123$ ls -l *.txt | awk &apos;&#123;sum+=$6&#125; END &#123;print sum&#125;&apos;--------------------------------------------------666581 从文件中找出长度大于80的行1awk &apos;length&gt;80&apos; log.txt 打印九九乘法表1seq 9 | sed &apos;H;g&apos; | awk -v RS=&apos;&apos; &apos;&#123;for(i=1;i&lt;=NF;i++)printf(&quot;%dx%d=%d%s&quot;, i, NR, i*NR, i==NR?&quot;\n&quot;:&quot;\t&quot;)&#125;&apos;]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>awk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux ls 命令]]></title>
    <url>%2F2019%2F03%2F26%2FLinux-ls-%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux ls命令用于显示指定工作目录下之内容（列出目前工作目录所含之文件及子目录)。 语法1ls [-alrtAFR] [name...] 参数 -a 显示所有文件及目录 (ls内定将文件名或目录名称开头为”.”的视为隐藏档，不会列出) -l 除文件名称外，亦将文件型态、权限、拥有者、文件大小等资讯详细列出 -r 将文件以相反次序显示(原定依英文字母次序) -t 将文件依建立时间之先后次序列出 -A 同 -a ，但不列出 “.” (目前目录) 及 “..” (父目录) -F 在列出的文件名称后加一符号；例如可执行档则加 “*”, 目录则加 “/“ -R 若目录下有文件，则以下之文件亦皆依序列出 实例列出根目录()下的所有目录：1234# ls /bin dev lib media net root srv upload wwwboot etc lib64 misc opt sbin sys usrhome lost+found mnt proc selinux tmp var 列出目前工作目录下所有名称是 s 开头的文件，越新的排越后面 :1ls -ltr s* 将 /bin 目录以下所有目录及文件详细资料列出 :1ls -lR /bin 列出目前工作目录下所有文件及目录；目录于名称后加 “/“, 可执行档于名称后加 “*” :1ls -AF]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>ls</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux rmdir 命令]]></title>
    <url>%2F2019%2F03%2F26%2FLinux-rmdir-%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux rmdir命令删除空的目录。 语法1rmdir [-p] dirName -p 是当子目录被删除后使它也成为空目录的话，则顺便一并删除。实例将工作目录下，名为 AAA 的子目录删除 :1rmdir AAA 在工作目录下的 BBB 目录中，删除名为 Test 的子目录。若 Test 删除后，BBB 目录成为空目录，则 BBB 亦予删除。1rmdir -p BBB/Test]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>rmdir</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux cd 命令]]></title>
    <url>%2F2019%2F03%2F26%2FLinux-cd-%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux cd命令用于切换当前工作目录至 dirName(目录参数)。其中 dirName 表示法可为绝对路径或相对路径。若目录名称省略，则变换至使用者的 home 目录 (也就是刚 login 时所在的目录)。另外，”~” 也表示为 home 目录 的意思，”.” 则是表示目前所在的目录，”..” 则表示目前目录位置的上一层目录。 语法1cd [dirName] dirName：要切换的目标目录。 实例跳到 /usr/bin/ :1cd /usr/bin 跳到自己的 home 目录 :1cd ~ 跳到目前目录的上上两层 :1cd ../..]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>cd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux mkdir 命令]]></title>
    <url>%2F2019%2F03%2F26%2FLinux-mkdir-%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux mkdir命令用于建立名称为 dirName 之子目录。 语法1mkdir [-p] dirName 参数说明 -p 确保目录名称存在，不存在的就建一个。 实例在工作目录下，建立一个名为 AAA 的子目录 :1mkdir AAA 在工作目录下的 BBB 目录中，建立一个名为 Test 的子目录。 若 BBB 目录原本不存在，则建立一个。（注：本例若不加 -p，且原本 BBB目录不存在，则产生错误。）1mkdir -p BBB/Test]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>mkdir</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux rm 命令]]></title>
    <url>%2F2019%2F03%2F26%2FLinux-rm-%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux rm命令用于删除一个文件或者目录。 语法1rm [options] name... 参数 -i 删除前逐一询问确认。 -f 即使原档案属性设为唯读，亦直接删除，无需逐一确认。 -r 将目录及以下之档案亦逐一删除。 实例删除文件可以直接使用rm命令，若删除目录则必须配合选项”-r”，例如：123456# rm test.txt rm：是否删除 一般文件 &quot;test.txt&quot;? y # rm homework rm: 无法删除目录&quot;homework&quot;: 是一个目录 # rm -r homework rm：是否删除 目录 &quot;homework&quot;? y 删除当前目录下的所有文件及目录，命令行为：1rm -r * 文件一旦通过rm命令删除，则无法恢复，所以必须格外小心地使用该命令。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>rm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux mv 命令]]></title>
    <url>%2F2019%2F03%2F26%2FLinux-mv-%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux mv命令用来为文件或目录改名、或将文件或目录移入其它位置。 语法12mv [options] source destmv [options] source... directory 参数说明 -i: 若指定目录已有同名文件，则先询问是否覆盖旧文件; -f: 在mv操作要覆盖某已有的目标文件时不给任何指示;mv参数设置与运行结果 命令格式 运行结果 mv 文件名 文件名 将源文件名改为目标文件名 mv 文件名 目录名 将文件移动到目标目录 mv 目录名 目录名 目标目录已存在，将源目录移动到目标目录；目标目录不存在则改名 mv 目录名 文件名 出错 实例将文件 aaa 更名为 bbb :1mv aaa bbb 将info目录放入logs目录中。注意，如果logs目录不存在，则该命令将info改名为logs。1mv info/ logs 再如将/usr/student下的所有文件和目录移到当前目录下，命令行为：1$ mv /usr/student/* .]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>mv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux grep 命令]]></title>
    <url>%2F2019%2F03%2F26%2FLinux-grep-%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux grep命令用于查找文件里符合条件的字符串。grep指令用于查找内容包含指定的范本样式的文件，如果发现某文件的内容符合所指定的范本样式，预设grep指令会把含有范本样式的那一列显示出来。若不指定任何文件名称，或是所给予的文件名为”-“，则grep指令会从标准输入设备读取数据。 语法1grep [-abcEFGhHilLnqrsvVwxy][-A&lt;显示列数&gt;][-B&lt;显示列数&gt;][-C&lt;显示列数&gt;][-d&lt;进行动作&gt;][-e&lt;范本样式&gt;][-f&lt;范本文件&gt;][--help][范本样式][文件或目录...] 参数 -a 或 –text : 不要忽略二进制的数据。 -A&lt;显示行数&gt; 或 –after-context=&lt;显示行数&gt; : 除了显示符合范本样式的那一列之外，并显示该行之后的内容。 -b 或 –byte-offset : 在显示符合样式的那一行之前，标示出该行第一个字符的编号。 -B&lt;显示行数&gt; 或 –before-context=&lt;显示行数&gt; : 除了显示符合样式的那一行之外，并显示该行之前的内容。 -c 或 –count : 计算符合样式的列数。 -C&lt;显示行数&gt; 或 –context=&lt;显示行数&gt;或-&lt;显示行数&gt; : 除了显示符合样式的那一行之外，并显示该行之前后的内容。 -d &lt;动作&gt; 或 –directories=&lt;动作&gt; : 当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作。 -e&lt;范本样式&gt; 或 –regexp=&lt;范本样式&gt; : 指定字符串做为查找文件内容的样式。 -E 或 –extended-regexp : 将样式为延伸的普通表示法来使用。 -f&lt;规则文件&gt; 或 –file=&lt;规则文件&gt; : 指定规则文件，其内容含有一个或多个规则样式，让grep查找符合规则条件的文件内容，格式为每行一个规则样式。 -F 或 –fixed-regexp : 将样式视为固定字符串的列表。 -G 或 –basic-regexp : 将样式视为普通的表示法来使用。 -h 或 –no-filename : 在显示符合样式的那一行之前，不标示该行所属的文件名称。 -H 或 –with-filename : 在显示符合样式的那一行之前，表示该行所属的文件名称。 -i 或 –ignore-case : 忽略字符大小写的差别。 -l 或 –file-with-matches : 列出文件内容符合指定的样式的文件名称。 -L 或 –files-without-match : 列出文件内容不符合指定的样式的文件名称。 -n 或 –line-number : 在显示符合样式的那一行之前，标示出该行的列数编号。 -o 或 –only-matching : 只显示匹配PATTERN 部分。 -q 或 –quiet或–silent : 不显示任何信息。 -r 或 –recursive : 此参数的效果和指定”-d recurse”参数相同。 -s 或 –no-messages : 不显示错误信息。 -v 或 –revert-match : 显示不包含匹配文本的所有行。 -V 或 –version : 显示版本信息。 -w 或 –word-regexp : 只显示全字符合的列。 -x –line-regexp : 只显示全列符合的列。 -y : 此参数的效果和指定”-i”参数相同。 实例 在当前目录中，查找后缀有 file 字样的文件中包含 test 字符串的文件，并打印出该字符串的行。此时，可以使用如下命令：1grep test *file 结果如下所示：1234$ grep test test* #查找前缀有“test”的文件包含“test”字符串的文件 testfile1:This a Linux testfile! #列出testfile1 文件中包含test字符的行 testfile_2:This is a linux testfile! #列出testfile_2 文件中包含test字符的行 testfile_2:Linux test #列出testfile_2 文件中包含test字符的行 以递归的方式查找符合条件的文件。例如，查找指定目录/etc/acpi 及其子目录（如果存在子目录的话）下所有文件中包含字符串”update”的文件，并打印出该字符串所在行的内容，使用的命令为：1grep -r update /etc/acpi 输出结果如下：1234567$ grep -r update /etc/acpi #以递归的方式查找“etc/acpi” #下包含“update”的文件 /etc/acpi/ac.d/85-anacron.sh:# (Things like the slocate updatedb cause a lot of IO.) Rather than /etc/acpi/resume.d/85-anacron.sh:# (Things like the slocate updatedb cause a lot of IO.) Rather than /etc/acpi/events/thinkpad-cmos:action=/usr/sbin/thinkpad-keys--update 反向查找。前面各个例子是查找并打印出符合条件的行，通过”-v”参数可以打印出不符合条件行的内容。查找文件名中包含 test 的文件中不包含test 的行，此时，使用的命令为：1grep -v test *test* 结果如下所示:123456789$ grep-v test* #查找文件名中包含test 的文件中不包含test 的行 testfile1:helLinux! testfile1:Linis a free Unix-type operating system. testfile1:Lin testfile_1:HELLO LINUX! testfile_1:LINUX IS A FREE UNIX-TYPE OPTERATING SYSTEM. testfile_1:THIS IS A LINUX TESTFILE! testfile_2:HELLO LINUX! testfile_2:Linux is a free unix-type opterating system.]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>grep</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux sed 命令]]></title>
    <url>%2F2019%2F03%2F25%2FLinux-sed-%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux sed命令是利用script来处理文本文件。sed可依照script的指令，来处理、编辑文本文件。Sed主要用来自动编辑一个或多个文件；简化对文件的反复操作；编写转换程序等。 语法1sed [-hnV][-e][-f][文本文件] 参数说明 -e或–expression=以选项中指定的script来处理输入的文本文件。 -f&lt;script文件&gt;或–file=&lt;script文件&gt; 以选项中指定的script文件来处理输入的文本文件。 -h或–help 显示帮助。 -n或–quiet或–silent 仅显示script处理后的结果。 -V或–version 显示版本信息。 参数 a ：新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)～ c ：取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！ d ：删除，因为是删除啊，所以 d 后面通常不接任何咚咚； i ：插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)； p ：打印，亦即将某个选择的数据印出。通常 p 会与参数 sed -n 一起运行～ s ：取代，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g 实例在testfile文件的第四行后添加一行，并将结果输出到标准输出，在命令行提示符下输入如下命令： 1sed -e 4a\newLine testfile 首先查看testfile中的内容如下：12345$ cat testfile #查看testfile 中的内容 HELLO LINUX! Linux is a free unix-type opterating system. This is a linux testfile! Linux test 使用sed命令后，输出结果如下：123456$ sed -e 4a\newline testfile #使用sed 在第四行后添加新字符串 HELLO LINUX! #testfile文件原有的内容 Linux is a free unix-type opterating system. This is a linux testfile! Linux test newline 以行为单位的新增/删除将 /etc/passwd 的内容列出并且列印行号，同时，请将第 2~5 行删除！ 12345[root@www ~]# nl /etc/passwd | sed &apos;2,5d&apos;1 root:x:0:0:root:/root:/bin/bash6 sync:x:5:0:sync:/sbin:/bin/sync7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown.....(后面省略)..... sed 的动作为 ‘2,5d’ ，那个 d 就是删除！因为 2-5 行给他删除了，所以显示的数据就没有 2-5 行罗～ 另外，注意一下，原本应该是要下达 sed -e 才对，没有 -e 也行啦！同时也要注意的是， sed 后面接的动作，请务必以 ‘’ 两个单引号括住喔！ 只要删除第 2 行1nl /etc/passwd | sed &apos;2d&apos; 要删除第 3 到最后一行1nl /etc/passwd | sed &apos;3,$d&apos; 在第二行后(亦即是加在第三行)加上『drink tea?』字样！123456[root@www ~]# nl /etc/passwd | sed &apos;2a drink tea&apos;1 root:x:0:0:root:/root:/bin/bash2 bin:x:1:1:bin:/bin:/sbin/nologindrink tea3 daemon:x:2:2:daemon:/sbin:/sbin/nologin.....(后面省略)..... 那如果是要在第二行前1nl /etc/passwd | sed &apos;2i drink tea&apos; 如果是要增加两行以上，在第二行后面加入两行字，例如 Drink tea or ….. 与 drink beer?12345678[root@www ~]# nl /etc/passwd | sed &apos;2a Drink tea or ......\&gt; drink beer ?&apos;1 root:x:0:0:root:/root:/bin/bash2 bin:x:1:1:bin:/bin:/sbin/nologinDrink tea or ......drink beer ?3 daemon:x:2:2:daemon:/sbin:/sbin/nologin.....(后面省略)..... 每一行之间都必须要以反斜杠『 \ 』来进行新行的添加喔！所以，上面的例子中，我们可以发现在第一行的最后面就有 \ 存在。 以行为单位的替换与显示将第2-5行的内容取代成为『No 2-5 number』呢？12345[root@www ~]# nl /etc/passwd | sed &apos;2,5c No 2-5 number&apos;1 root:x:0:0:root:/root:/bin/bashNo 2-5 number6 sync:x:5:0:sync:/sbin:/bin/sync.....(后面省略)..... 透过这个方法我们就能够将数据整行取代了！ 仅列出 /etc/passwd 文件内的第 5-7 行1234[root@www ~]# nl /etc/passwd | sed -n &apos;5,7p&apos;5 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin6 sync:x:5:0:sync:/sbin:/bin/sync7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown 可以透过这个 sed 的以行为单位的显示功能， 就能够将某一个文件内的某些行号选择出来显示。 数据的搜寻并显示搜索 /etc/passwd有root关键字的行12345678nl /etc/passwd | sed &apos;/root/p&apos;1 root:x:0:0:root:/root:/bin/bash1 root:x:0:0:root:/root:/bin/bash2 daemon:x:1:1:daemon:/usr/sbin:/bin/sh3 bin:x:2:2:bin:/bin:/bin/sh4 sys:x:3:3:sys:/dev:/bin/sh5 sync:x:4:65534:sync:/bin:/bin/sync....下面忽略 如果root找到，除了输出所有行，还会输出匹配行。 使用-n的时候将只打印包含模板的行。12nl /etc/passwd | sed -n &apos;/root/p&apos;1 root:x:0:0:root:/root:/bin/bash 数据的搜寻并删除删除/etc/passwd所有包含root的行，其他行输出12345nl /etc/passwd | sed &apos;/root/d&apos;2 daemon:x:1:1:daemon:/usr/sbin:/bin/sh3 bin:x:2:2:bin:/bin:/bin/sh....下面忽略#第一行的匹配root已经删除了 数据的搜寻并执行命令搜索/etc/passwd,找到root对应的行，执行后面花括号中的一组命令，每个命令之间用分号分隔，这里把bash替换为blueshell，再输出这行：12nl /etc/passwd | sed -n &apos;/root/&#123;s/bash/blueshell/;p;q&#125;&apos; 1 root:x:0:0:root:/root:/bin/blueshell 最后的q是退出。 数据的搜寻并替换除了整行的处理模式之外， sed 还可以用行为单位进行部分数据的搜寻并取代。基本上 sed 的搜寻与替代的与 vi 相当的类似！他有点像这样：1sed &apos;s/要被取代的字串/新的字串/g&apos; 先观察原始信息，利用 /sbin/ifconfig 查询 IP123456[root@www ~]# /sbin/ifconfig eth0eth0 Link encap:Ethernet HWaddr 00:90:CC:A6:34:84inet addr:192.168.1.100 Bcast:192.168.1.255 Mask:255.255.255.0inet6 addr: fe80::290:ccff:fea6:3484/64 Scope:LinkUP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1.....(以下省略)..... 本机的ip是192.168.1.100。将 IP 前面的部分予以删除12[root@www ~]# /sbin/ifconfig eth0 | grep &apos;inet addr&apos; | sed &apos;s/^.*addr://g&apos;192.168.1.100 Bcast:192.168.1.255 Mask:255.255.255.0 接下来则是删除后续的部分，亦即： 192.168.1.100 Bcast:192.168.1.255 Mask:255.255.255.0将 IP 后面的部分予以删除12[root@www ~]# /sbin/ifconfig eth0 | grep &apos;inet addr&apos; | sed &apos;s/^.*addr://g&apos; | sed &apos;s/Bcast.*$//g&apos;192.168.1.100 多点编辑一条sed命令，删除/etc/passwd第三行到末尾的数据，并把bash替换为blueshell123nl /etc/passwd | sed -e &apos;3,$d&apos; -e &apos;s/bash/blueshell/&apos;1 root:x:0:0:root:/root:/bin/blueshell2 daemon:x:1:1:daemon:/usr/sbin:/bin/sh -e表示多点编辑，第一个编辑命令删除/etc/passwd第三行到末尾的数据，第二条命令搜索bash替换为blueshell。 直接修改文件内容(危险动作)sed 可以直接修改文件的内容，不必使用管道命令或数据流重导向！ 不过，由於这个动作会直接修改到原始的文件，所以请你千万不要随便拿系统配置来测试！ 我们还是使用文件 regular_express.txt 文件来测试看看吧！regular_express.txt 文件内容如下：1234567[root@www ~]# cat regular_express.txt runoob.google.taobao.facebook.zhihu-weibo- 利用 sed 将 regular_express.txt 内每一行结尾若为 . 则换成 !12345678[root@www ~]# sed -i &apos;s/\.$/\!/g&apos; regular_express.txt[root@www ~]# cat regular_express.txt runoob!google!taobao!facebook!zhihu-weibo- :q:q利用 sed 直接在 regular_express.txt 最后一行加入 # This is a test:123456789[root@www ~]# sed -i &apos;$a # This is a test&apos; regular_express.txt[root@www ~]# cat regular_express.txt runoob!google!taobao!facebook!zhihu-weibo-# This is a test 由於 $ 代表的是最后一行，而 a 的动作是新增，因此该文件最后新增 # This is a test！ sed 的 -i 选项可以直接修改文件内容，这功能非常有帮助！举例来说，如果你有一个 100 万行的文件，你要在第 100 行加某些文字，此时使用 vim 可能会疯掉！因为文件太大了！那怎办？就利用 sed 啊！透过 sed 直接修改/取代的功能，你甚至不需要使用 vim 去修订！]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>sed</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux cat 命令]]></title>
    <url>%2F2019%2F03%2F25%2FLinux-cat-%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[cat 命令用于连接文件并打印到标准输出设备上。 语法格式1cat [-AbeEnstTuv] [--help] [--version] fileName 参数说明-n 或 –number：由 1 开始对所有输出的行数编号。 -b 或 –number-nonblank：和 -n 相似，只不过对于空白行不编号。 -s 或 –squeeze-blank：当遇到有连续两行以上的空白行，就代换为一行的空白行。 -v 或 –show-nonprinting：使用 ^ 和 M- 符号，除了 LFD 和 TAB 之外。 -E 或 –show-ends : 在每行结束处显示 $。 -T 或 –show-tabs: 将 TAB 字符显示为 ^I。 -A, –show-all：等价于 -vET。 -e：等价于”-vE”选项； -t：等价于”-vT”选项； 实例把 textfile1 的文档内容加上行号后输入 textfile2 这个文档里：1cat -n textfile1 &gt; textfile2 把 textfile1 和 textfile2 的文档内容加上行号（空白行不加）之后将内容附加到 textfile3 文档里：1cat -b textfile1 textfile2 &gt;&gt; textfile3 批量合并相似文件test1、test2、test3…..1cat text* &gt;&gt; testfile 清空 /etc/test.txt 文档内容：1cat /dev/null &gt; /etc/test.txt cat 也可以用来制作镜像文件。例如要制作软盘的镜像文件，将软盘放好后输入：1cat /dev/fd0 &gt; OUTFILE 相反的，如果想把 image file 写到软盘，输入：1cat IMG_FILE &gt; /dev/fd0 注 OUTFILE 指输出的镜像文件名。 IMG_FILE 指镜像文件。 若从镜像文件写回 device 时，device 容量需与相当。 通常用制作开机磁片。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>cat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于R语言的相关性显著性检验]]></title>
    <url>%2F2019%2F01%2F14%2F%E5%9F%BA%E4%BA%8ER%E8%AF%AD%E8%A8%80%E7%9A%84%E7%9B%B8%E5%85%B3%E6%80%A7%E6%98%BE%E8%91%97%E6%80%A7%E6%A3%80%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[作者介绍：白马长枪儒雅将原文链接：https://blog.csdn.net/u012429555/article/details/78905585已授权转载 &#160; &#160; &#160; &#160;p 值可以解释如下:一个很小的p 值表示，在预测变量和响应变量之间的真实关系未知的情况下，不太可能完全由于偶然而观察到预测变量和响应变量之间的强相关。因此，如果看到一个很小的p 值，就可以推断预测变量和响应变量问存在关联。如果p 值足够小，我们便拒绝零假设( reject the null hypothesis) 也就是声明X 和Y 之间存在关系。 一、 相关相关系数可以用来描述定量变量之间的关系。相关系数的符号（）表明关系的方向（正相关或负相关），其值的大小表示关系的强弱程度（完全不相关时为0，完全相关时为1）我们将使用R基础安装中的 state.x77 数据集，它提供了美国50个州在1977年的人口、收入、文盲率、预期寿命、谋杀率和高中毕业率数据。数据集中还收录了气温和土地面积数据，但为了节约空间，这里将其丢弃。你可以使用help(state.x77)了解数据集的更多信息。除了基础安装以外，我们还将使用psych和ggm包。 12345678install.packages(&quot;psych&quot;)library(psych) install.packages(&quot;igraph&quot;)library(igraph)install.packages(&quot;ggm&quot;)library(ggm) 12345678910111213相关的类型R可以计算多种相关系数，包括Pearson相关系数、Spearman相关系数、Kendall相关系数、偏相关系数、多分格（polychoric）相关系数和多系列（polyserial）相关系数。1. Pearson、Spearman和Kendall相关 Pearson积差相关系数衡量了两个定量变量之间的线性相关程度。Spearman等级相关系数则衡 量分级定序变量之间的相关程度。Kendall’s Tau相关系数也是一种非参数的等级相关度量。 cor()函数可以计算这三种相关系数，而cov()函数可用来计算协方差。 cor(x,use = ,method = ) x 矩阵或数据框 use 指定缺失数据的处理方式。可选的方式为all.obs（假设不存在缺失数据——遇到缺失数据时将报 错）、everything（遇到缺失数据时，相关系数的计算结果将被设为missing）、complete.obs （行删除）以及 pairwise.complete.obs（成对删除，pairwise deletion） method 指定相关系数的类型。可选类型为pearson、spearman或kendall 协方差和相关系数 123456789101112131415161718192021222324252627282930states&lt;-state.x77[,1:6]cov(states) &gt; cov(states) Population Income Illiteracy Life Exp Murder Population 19931683.7588 571229.7796 292.8679592 -407.8424612 5663.523714 Income 571229.7796 377573.3061 -163.7020408 280.6631837 -521.894286 Illiteracy 292.8680 -163.7020 0.3715306 -0.4815122 1.581776 Life Exp -407.8425 280.6632 -0.4815122 1.8020204 -3.869480 Murder 5663.5237 -521.8943 1.5817755 -3.8694804 13.627465 HS Grad -3551.5096 3076.7690 -3.2354694 6.3126849 -14.549616 HS Grad Population -3551.509551 Income 3076.768980 Illiteracy -3.235469 Life Exp 6.312685 Murder -14.549616 HS Grad 65.237894 cor(states)cor(states,method = &quot;spearman&quot;) Population Income Illiteracy Life Exp Murder HS Grad Population 1.0000000 0.1246098 0.3130496 -0.1040171 0.3457401 -0.3833649 Income 0.1246098 1.0000000 -0.3145948 0.3241050 -0.2174623 0.5104809 Illiteracy 0.3130496 -0.3145948 1.0000000 -0.5553735 0.6723592 -0.6545396 Life Exp -0.1040171 0.3241050 -0.5553735 1.0000000 -0.7802406 0.5239410 Murder 0.3457401 -0.2174623 0.6723592 -0.7802406 1.0000000 -0.4367330 HS Grad -0.3833649 0.5104809 -0.6545396 0.5239410 -0.4367330 1.0000000 首个语句计算了方差和协方差，第二个语句则计算了Pearson积差相关系数，而第三个语句计算了Spearman等级相关系数。举例来说，我们可以看到收入和高中毕业率之间存在很强的正相关，而文盲率和预期寿命之间存在很强的负相关 请注意，在默认情况下得到的结果是一个方阵（所有变量之间两两计算相关）。你同样可以计算非方形的相关矩阵。当你对某一组变量与另外一组变量之间的关系感兴趣时，cor()函数的这种用法是非常实用的。注意，上述结果并未指明相关系数是否显著不为0（即，根据样本数据是否有足够的证据得出总体相关系数不为0的结论）。由于这个原因，你需要对相关系数进行显著性检验 二、 偏相关偏相关是指在控制一个或多个定量变量时，另外两个定量变量之间的相互关系。你可以使用ggm包中的pcor()函数计算偏相关系数。ggm包没有被默认安装，在第一次使用之前需要先进行安装。函数调用格式为：pcor(u,s)其中的u是一个数值向量，前两个数值表示要计算相关系数的变量下标，其余的数值为条件变量（即要排除影响的变量）的下标。S为变量的协方差阵。 12library(ggm)pcor(c(1,5,2,3,6),cov(states)) 1[1] 0.3462724 本例中，在控制了收入、文盲率和高中毕业率的影响时，人口和谋杀率之间的相关系数为0.346。偏相关系数常用于社会科学的研究中。 三、 其他类型的相关polycor包中的hetcor()函数可以计算一种混合的相关矩阵，其中包括数值型变量的Pearson积差相关系数、数值型变量和有序变量之间的多系列相关系数、有序变量之间的多分格相关系数以及二分变量之间的四分相关系数。多系列、多分格和四分相关系数都假设有序变量或二分变量由潜在的正态分布导出。请相关性的显著性检验在计算好相关系数以后，如何对它们进行统计显著性检验呢？常用的原假设为变量间不相关（即总体的相关系数为0）。cor.test()函数对单个的Pearson、Spearman和Kendall相关系数进行检验:cor.test(x,y,alternative=,method=)其中的x和y为要检验相关性的变量，alternative则用来指定进行双侧检验或单侧检验（取值为”two.side”、”less”或”greater”），而method用以指定要计算的相关类型（”pearson”、”kendall”或”spearman”）。当研究的假设为总体的相关系数小于0时，请使用alternative=”less”在研究的假设为总体的相关系数大于0时，应使用alternative=”greater”。 #默认情况下：为alternative=”two.side”（总体相关系数不等于0） 1cor.test(states[,3],states[,5]) 12345678910Pearson&apos;s product-moment correlationdata: states[, 3] and states[, 5]t = 6.8479, df = 48, p-value = 1.258e-08alternative hypothesis: true correlation is not equal to 095 percent confidence interval: 0.5279280 0.8207295 sample estimates: cor 0.7029752 这段代码检验了预期寿命和谋杀率的Pearson相关系数为0的原假设。假设总体的相关度为0，则预计在一千万次中只会有少于一次的机会见到0.703这样大的样本相关度（即p = 1.258e08）。由于这种情况几乎不可能发生，所以你可以拒绝原假设，从而支持了要研究的猜想，即预期寿命和谋杀率之间的总体相关度不为0。遗憾的是，cor.test每次只能检验一种相关关系。但幸运的是，psych包中提供的corr.test()函数可以一次做更多事情。。corr.test()函数可以为Pearson、Spearman或Kendall相关计算相关矩阵和显著性水平 corr.test 计算相关矩阵并进行显著性检验 corr.test(states,use = “complete”) 1corr.test(states,use = &quot;complete&quot;) 123456789101112131415161718192021Call:corr.test(x = states, use = &quot;complete&quot;)Correlation matrix Population Income Illiteracy Life Exp Murder HS GradPopulation 1.00 0.21 0.11 -0.07 0.34 -0.10Income 0.21 1.00 -0.44 0.34 -0.23 0.62Illiteracy 0.11 -0.44 1.00 -0.59 0.70 -0.66Life Exp -0.07 0.34 -0.59 1.00 -0.78 0.58Murder 0.34 -0.23 0.70 -0.78 1.00 -0.49HS Grad -0.10 0.62 -0.66 0.58 -0.49 1.00Sample Size [1] 50Probability values (Entries above the diagonal are adjusted for multiple tests.) Population Income Illiteracy Life Exp Murder HS GradPopulation 0.00 0.59 1.00 1.0 0.10 1Income 0.15 0.00 0.01 0.1 0.54 0Illiteracy 0.46 0.00 0.00 0.0 0.00 0Life Exp 0.64 0.02 0.00 0.0 0.00 0Murder 0.01 0.11 0.00 0.0 0.00 0HS Grad 0.50 0.00 0.00 0.0 0.00 0To see confidence intervals of the correlations, print with the short=FALSE option 12345参数use=的取值可为&quot;pairwise&quot;或&quot;complete&quot;（分别表示对缺失值执行成对删除或行删除）。参数method=的取值可为&quot;pearson&quot;（默认值）、&quot;spearman&quot;或&quot;kendall&quot;。人口数量和高中毕业率的相关系数（-0.10）并不显著地不为0（p = 0.5）其他显著性检验，我们关注了偏相关系数。在多元正态性的假设下，psych包中的pcor.test()函数①可以用来检验在控制一个或多个额外变量时两个变量之间的条件独立性。使用格式为：其中的r是由pcor()函数计算得到的偏相关系数，q为要控制的变量数（以数值表示位置），n为样本大小。在结束这个话题之前应当指出的是，psych包中的r.test()函数提供了多种实用的显著性检验方法。此函数可用来检验： 某种相关系数的显著性； 两个独立相关系数的差异是否显著； 两个基于一个共享变量得到的非独立相关系数的差异是否显著； 两个基于完全不同的变量得到的非独立相关系数的差异是否显著。 补充知识： 一 、相关性和显著性的关系： 关系的显著性（the significance of the relationship）：指两（或多）变量之间关系的统计显著水平，一般要求p &lt; 0.05。这是解释的第一步，如果不显著（p &gt; 0.05）、不管其相关系数（回归系数或其它描述关系强度的统计量）多强（这在小样本的情况下会发生），都没有继续讨论的意义，因为在总体中这种关系存在的可能性很低，如接受这种关系的风险太大（即Type I错误）。 关系的强度（the strength of the relationship）：指相关系数（或其它类似统计量）的大小。以相关系数为例，一般认为0.3以下为弱相关、0.3-0.7之间为中相关、0.7-1.0为强相关。这种分类也适用于其它标准化统计量（如标准回归系数, standardized regression coefficient，在SPSS中叫BETA）。大家知道，这些标准化的统计量的平方描述了两（或多）个变量之间的重合部分（如我最近详细解释的回归模型R2描述了自变量对因变量的解释部分），从那个角度来看，弱相关的变量之间的重合不到10％、中相关变量之间的重合在10－50%，强相关变量之间的重合在50％以上。 关系的方向（the direction of the relationship）：指相关系数（或其它类似统计量）的正负符号。如果原先的假设是单尾（one-tailed），如“上网会减少社交时间”、“上网会增加孤独感”等，那么其相关系数的方向就十分重要。（从可证伪性原则来看，单尾假设比双尾假设更好。）当一对变量的关系是显著并强烈、但是其方向与假设相反，该研究假设也必须被拒绝。当然研究者应该深入分析这种情况为何会发生。 关系的形式（the form of the relationship）：指变量之间的关系是线性（linear）还是非线性（nonlinear）。上述统计量描述的都是线性关系，如果不显著、显著而弱、显著并强烈但反方向，也许其真正的关系不是线性而是非线性，所以我们不能简单地收工回家，而要探索其非线性关系。当然，后者更复杂、对于没有良好的理论和方法训练的研究者更是容易掉进种种陷阱。 二、 只有显著性水平显著时，相关系数才是可信的 &#160; &#160; &#160; &#160;也就说只看相关系数是说明不了问题的，还得看显著性，而且还是显著性水平显著的时候，就可以说明相关系数论证的点可信的，我们知道相关系数有以下含义： 这里，,是一个可以表征 x 和 y 之间线性关系紧密程度的量。它具有两个性质： 的充要条件是，存在常数a，b，使得由性质衍生： 相关系数定量地刻画了 X 和 Y的相关程度，即 越大，相关程度越大；对应相关程度最低； X 和Y 完全相关的含义是在概率为1的意义下存在线性关系，于是 是一个可以表征X 和Y 之间线性关系紧密程度的量。当较大时，通常说X 和Y相关程度较好；当 较小时，通常说X 和Y相关程度较差；当X和Y不相关，通常认为X和Y之间不存在线性关系，但并不能排除X和Y之间可能存在其他关系。 若X和Y不相关通常认为X和Y之间不存在线性关系，但并不能排除X和Y之间可能存在其他关系；若则X和Y不相关。若X和Y独立，则必有因而X和Y不相关；若X和Y不相关，则仅仅是不存在线性关系，可能存在其他关系，如X和Y不独立。 看例图： 显著系数P：P值即概率，反映某一事件发生的可能性大小。统计学根据显著性检验方法所得到的P 值，一般以P &lt; 0.05 为有统计学差异， P&lt;0.01 为有显著统计学差异，P&lt;0.001为有极其显著的统计学差异。 P值 碰巧的概率 对无效假设 统计意义 P&gt;0.05 碰巧出现的可能性大于5% 不能否定无效假设 两组差别无显著意义 P&lt;0.05 碰巧出现的可能性小于5% 可以否定无效假设 两组差别有显著意义 P &lt;0.01 碰巧出现的可能性小于1% 可以否定无效假设 两者差别有非常显著意义]]></content>
      <categories>
        <category>R</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>相关性检验</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[散点图矩阵]]></title>
    <url>%2F2019%2F01%2F07%2F%E6%95%A3%E7%82%B9%E5%9B%BE%E7%9F%A9%E9%98%B5_splom%2F</url>
    <content type="text"><![CDATA[12library(lattice)splom(mtcars[c(1,3,4,5)])]]></content>
      <categories>
        <category>R</category>
      </categories>
      <tags>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[power Bi 预测]]></title>
    <url>%2F2018%2F11%2F18%2Fpower-Bi-%E9%A2%84%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[目前只针对基于时间序列的折线图可用]]></content>
      <categories>
        <category>Power BI</category>
      </categories>
      <tags>
        <tag>Power BI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[power bi pro 发布 web 共享]]></title>
    <url>%2F2018%2F11%2F18%2Fpower-bi-pro-%E5%8F%91%E5%B8%83-web-%E5%85%B1%E4%BA%AB%2F</url>
    <content type="text"><![CDATA[之前制作的 Power BI 文件都放在 GitHub 里面，可操作性差 点击 超链接 进入 GitHub → 选择文件下载 → 本地打开 竟然如此麻烦，还是看看效果图片就好 现在！没错，就是现在！可以网页一步到位，power bi web 共享了解一下？ power bi pro 可以实现 web 共享，免费试用60天]]></content>
      <categories>
        <category>Power BI</category>
      </categories>
      <tags>
        <tag>Power BI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PPT 渐变字体练习]]></title>
    <url>%2F2018%2F10%2F29%2FPPT-%E6%B8%90%E5%8F%98%E5%AD%97%E4%BD%93%E7%BB%83%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[点击下载]]></content>
      <categories>
        <category>PPT</category>
      </categories>
      <tags>
        <tag>PPT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Power BI 第二届可视化大赛]]></title>
    <url>%2F2018%2F10%2F13%2FPower-BI-%E7%AC%AC%E4%BA%8C%E5%B1%8A%E5%8F%AF%E8%A7%86%E5%8C%96%E5%A4%A7%E8%B5%9B%2F</url>
    <content type="text"><![CDATA[Power BI 第二届可视化大赛 官方提供大赛数据 虚拟企业示例数据，点击下载 微软示例数据库 - Adventure Works 微软Azure SQL Database数据源（使用此数据源，除了其它奖项外，还有机会获得ADS（Azure Data Service）特别奖）： —服务器：pbicontest.database.chinacloudapi.cn —数据库：pbiDB —用户名：pbiguest —密码：1234#P@sd powerbi第二届可视化大赛作品展示]]></content>
      <categories>
        <category>Power BI</category>
      </categories>
      <tags>
        <tag>Power BI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[magrittr 管道操作]]></title>
    <url>%2F2018%2F10%2F09%2Fmagrittr-%E7%AE%A1%E9%81%93%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[magrittr 相关文章收集magrittr 管道操作能极大程度的简化数据处理，数据结构清晰明了 R语言中管道操作 %&gt;%, %T&gt;%, %$% 和 %&lt;&gt;%magrittr 官方开发文档magrittr GitHub development pageand more… magrittr - Ceci n’est pas un pipeDescriptionThe magrittr package offers a set of operators which promote semantics that will improve your code by structuring sequences of data operations left-to-right (as opposed to from the inside and out) avoiding nested function calls minimizing the need for local variables and function definitions, and making it easy to add steps anywhere in the sequence of operations. The operators pipe their left-hand side values forward into expressions that appear on the right-hand side, i.e. one can replace f(x) with x %&gt;% f, where %&gt;% is the (main) pipe-operator. Consider the example below. Four operations are performed to arrive at the desired data set, and they are written in a natural order: the same as the order of execution. Also, no temporary variables are needed. If yet another operation is required, it is straight-forward to add to the sequence of operations whereever it may be needed. For a more detailed introduction see the vignette (vignette(“magrittr”)) or the documentation pages for the available operators:1234%&gt;% forward-pipe operator.%T&gt;% tee operator.%&lt;&gt;% compound assignment pipe-operator.%$% exposition pipe-operator. Examples123456789## Not run: the_data &lt;- read.csv(&apos;/path/to/data/file.csv&apos;) %&gt;% subset(variable_a &gt; x) %&gt;% transform(variable_c = variable_a/veraiable_b) %&gt;% head(100)## End(Not run) Introduction and basicsAt first encounter, you may wonder whether an operator such as %&gt;% can really be all that beneficial; but as you may notice, it semantically changes your code in a way that makes it more intuitive to both read and write. Consider the following example, in which the mtcars dataset shipped with R is munged a little. 1234567library(magrittr)car_data &lt;- mtcars %&gt;% subset(hp &gt; 100) %&gt;% aggregate(. ~ cyl, data = ., FUN = . %&gt;% mean %&gt;% round(2)) %&gt;% transform(kpl = mpg %&gt;% multiply_by(0.4251)) %&gt;% print 1234 cyl mpg disp hp drat wt qsec vs am gear carb kpl1 4 25.90 108.05 111.00 3.94 2.15 17.75 1.00 1.00 4.50 2.00 11.0100902 6 19.74 183.31 122.29 3.59 3.12 17.98 0.57 0.43 3.86 3.43 8.3914743 8 15.10 353.10 209.21 3.23 4.00 16.77 0.00 0.14 3.29 3.50 6.419010 We start with a value, here mtcars (a data.frame). Based on this, we first extract a subset, then we aggregate the information based on the number of cylinders, and then we transform the dataset by adding a variable for kilometers per liter as supplement to miles per gallon. Finally we print the result before assigning it. Note how the code is arranged in the logical order of how you think about the task: data-&gt;transform-&gt;aggregate, which is also the same order as the code will execute. It’s like a recipe – easy to read, easy to follow! A horrific alternative would be to write1234car_data &lt;- transform(aggregate(. ~ cyl, data = subset(mtcars, hp &gt; 100), FUN = function(x) round(mean(x, 2))), kpl = mpg*0.4251) There is a lot more clutter with parentheses, and the mental task of deciphering the code is more challenging—in particular if you did not write it yourself. Note also how “building” a function on the fly for use in aggregate is very simple in magrittr: rather than an actual value as left-hand side in pipeline, just use the placeholder. This is also very useful in R’s *apply family of functions. Granted: you may make the second example better, perhaps throw in a few temporary variables (which is often avoided to some degree when using magrittr), but one often sees cluttered lines like the ones presented. And here is another selling point. Suppose I want to quickly want to add another step somewhere in the process. This is very easy in the to do in the pipeline version, but a little more challenging in the “standard” example. The combined example shows a few neat features of the pipe (which it is not): By default the left-hand side (LHS) will be piped in as the first argument of the function appearing on the right-hand side (RHS). This is the case in the subset and transform expressions. %&gt;% may be used in a nested fashion, e.g. it may appear in expressions within arguments. This is used in the mpg to kpl conversion. When the LHS is needed at a position other than the first, one can use the dot,’.’, as placeholder. This is used in the aggregate expression. The dot in e.g. a formula is not confused with a placeholder, which is utilized in the aggregate expression. Whenever only one argument is needed, the LHS, then one can omit the empty parentheses. This is used in the call to print (which also returns its argument). Here, LHS %&gt;% print(), or even LHS %&gt;% print(.) would also work. A pipeline with a dot (.) as LHS will create a unary function. This is used to define the aggregator function. One feature, which was not utilized above is piping into anonymous functions, or lambdas. This is possible using standard function definitions, e.g.123456car_data %&gt;% (function(x) &#123; if (nrow(x) &gt; 2) rbind(head(x, 1), tail(x, 1)) else x &#125;) 123 cyl mpg disp hp drat wt qsec vs am gear carb kpl1 4 26 108 111 4 2 18 1 1 4 2 11.05263 8 15 350 192 3 4 17 0 0 3 4 6.3765 However, magrittr also allows a short-hand notation:123456car_data %&gt;%&#123; if (nrow(.) &gt; 0) rbind(head(., 1), tail(., 1)) else .&#125; 123 cyl mpg disp hp drat wt qsec vs am gear carb kpl1 4 26 108 111 4 2 18 1 1 4 2 11.05263 8 15 350 192 3 4 17 0 0 3 4 6.3765 Since all right-hand sides are really “body expressions” of unary functions, this is only the natural extension the simple right-hand side expressions. Of course longer and more complex functions can be made using this approach. In the first example the anonymous function is enclosed in parentheses. Whenever you want to use a function- or call-generating statement as right-hand side, parentheses are used to evaluate the right-hand side before piping takes place. Another, less useful example is:11:10 %&gt;% (substitute(f(), list(f = sum))) 1[1] 55 Additional pipe operatorsmagrittr also provides three related pipe operators. These are not as common as %&gt;% but they become useful in special cases. The “tee” operator, %T&gt;% works like %&gt;%, except it returns the left-hand side value, and not the result of the right-hand side operation. This is useful when a step in a pipeline is used for its side-effect (printing, plotting, logging, etc.). As an example (where the actual plot is omitted here): 1234rnorm(200) %&gt;%matrix(ncol = 2) %T&gt;%plot %&gt;% # plot usually does not return anything. colSums 1[1] -4.835279 -5.274882 The “exposition” pipe operator, %$% exposes the names within the left-hand side object to the right-hand side expression. Essentially, it is a short-hand for using the with functions (and the same left-hand side objects are accepted). This operator is handy when functions do not themselves have a data argument, as for example lm and aggregate do. Here are a few examples as illustration:123456iris %&gt;% subset(Sepal.Length &gt; mean(Sepal.Length)) %$% cor(Sepal.Length, Sepal.Width)data.frame(z = rnorm(100)) %$% ts.plot(z) 1[1] 0.3361992 Finally, the compound assignment pipe operator %&lt;&gt;% can be used as the first pipe in a chain. The effect will be that the result of the pipeline is assigned to the left-hand side object, rather than returning the result as usual. It is essentially shorthand notation for expressions like foo % bar %&gt;% baz, which boils down to foo %&lt;&gt;% bar %&gt;% baz. Another example is1iris$Sepal.Length %&lt;&gt;% sqrt The %&lt;&gt;% can be used whenever expr &lt;- … makes sense, e.g. x %&lt;&gt;% foo %&gt;% bar x[1:10] %&lt;&gt;% foo %&gt;% bar x$baz %&lt;&gt;% foo %&gt;% bar AliasesIn addition to the %&gt;%-operator, magrittr provides some aliases for other operators which make operations such as addition or multiplication fit well into the magrittr-syntax. As an example, consider:12345678rnorm(1000) %&gt;% multiply_by(5) %&gt;% add(5) %&gt;% &#123; cat(&quot;Mean:&quot;, mean(.), &quot;Variance:&quot;, var(.), &quot;\n&quot;) head(.) &#125; 12Mean: 4.912365 Variance: 24.46778 [1] 5.853147 3.923652 7.802787 10.208513 2.239128 3.177795 which could be written in more compact form as12345rnorm(100) %&gt;% `*`(5) %&gt;% `+`(5) %&gt;% &#123; cat(&quot;Mean:&quot;, mean(.), &quot;Variance:&quot;, var(.), &quot;\n&quot;) head(.)&#125; 12Mean: 5.443435 Variance: 30.92747 [1] 2.7712630 1.9156065 2.9230592 7.8741192 3.2132655 0.1729982 To see a list of the aliases, execute e.g. ?multiply_by.]]></content>
  </entry>
  <entry>
    <title><![CDATA[Markdown 添加在线视频]]></title>
    <url>%2F2018%2F10%2F08%2FMarkdown-%E6%B7%BB%E5%8A%A0%E5%9C%A8%E7%BA%BF%E8%A7%86%E9%A2%91%2F</url>
    <content type="text"><![CDATA[通用代码1&lt;iframe height=400 width=700 src=&apos;http://music.163.com/m/mv?id=10770095&amp;userid=340573904&apos; frameborder=0 &apos;allowfullscreen&apos;&gt;&lt;/iframe&gt; 修改的src后的链接即可]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VLOOKUP 函数]]></title>
    <url>%2F2018%2F10%2F08%2FVLOOKUP-%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[如果需要在表格或区域中按行查找内容，可使用 VLOOKUP，它是一个查找和引用函数。例如，按部件号查找汽车部件的价格。在这一最简单的形式中，VLOOKUP 函数表示：=VLOOKUP（要查找的值、要在其中查找值的区域、区域中包含返回值的列号、精确匹配或近似匹配 – 指定为 0/FALSE 或 1/TRUE）。 使用 VLOOKUP 函数在表中查找值。语法VLOOKUP (lookup_value, table_array, col_index_num, [range_lookup]) 例如：=VLOOKUP(105,A2:C7,2,TRUE)=VLOOKUP(“袁”,B2:E7,2,FALSE) 参数名称 说明 lookup_value （必需参数） 要查找的值。要查找的值必须位于 table-array 中指定的单元格区域的第一列中。 例如，如果 table-array 指定的单元格为 B2:D7，则 lookup_value 必须位于列 B 中。请参见下图。Lookup_value 可以是值，也可以是单元格引用。 Table_array （必需参数） VLOOKUP 在其中搜索 lookup_value 和返回值的单元格区域。 该单元格区域中的第一列必须包含 lookup_value（例如，下图中的“姓氏”）。此单元格区域中还需要包含您要查找的返回值（例如，下图中的“名字”）。 了解如何选择工作表中的区域。 col_index_num （必需参数） 其中包含返回值的单元格的编号（table-array 最左侧单元格为 1 开始编号）。 range_lookup （可选参数） 一个逻辑值，该值指定希望 VLOOKUP 查找近似匹配还是精确匹配： TRUE 假定表中的第一列按数字或字母排序，然后搜索最接近的值。这是未指定值时的默认方法。 FALSE 在第一列中搜索精确值。 需要四条信息才能构建 VLOOKUP 语法：1、要查找的值，也被称为查阅值。2、查阅值所在的区域。请记住，查阅值应该始终位于所在区域的第一列，这样 VLOOKUP 才能正常工作。例如，如果查阅值位于单元格 C2 内，那么您的区域应该以 C 开头。3、区域中包含返回值的列号。例如，如果指定 B2：D11 作为区域，那么应该将 B 算作第一列，C 作为第二列，以此类推。4、（可选）如果需要返回值的近似匹配，可以指定 TRUE；如果需要返回值的精确匹配，则指定 FALSE。如果没有指定任何内容，默认值将始终为 TRUE 或近似匹配。 现在将上述所有内容集中在一起，如下所示：=VLOOKUP（查阅值、包含查阅值的区域、区域中包含返回值的列号以及（可选）为近似匹配指定 TRUE 或者为精确匹配指定 FALSE）。 例如： 文章来源：excel官方文档]]></content>
      <categories>
        <category>excel</category>
      </categories>
      <tags>
        <tag>excel</tag>
        <tag>vlookup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于R语言的用户贷款风险预测]]></title>
    <url>%2F2018%2F10%2F04%2F%E5%9F%BA%E4%BA%8ER%E8%AF%AD%E8%A8%80%E7%9A%84%E7%94%A8%E6%88%B7%E8%B4%B7%E6%AC%BE%E9%A3%8E%E9%99%A9%E9%A2%84%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[作者介绍：皮吉斯，热爱R语言，知乎号：皮吉斯已授权转载 本次的分析数据来自kaggle数据竞赛平台的 “give me some credit” 竞赛项目。任务是提高模型精度AUC。本次分析用到了多种算法，分别有：逻辑回归，cart决策树，神经网络，xgboost，随机森林。通过多种模型相互对比，最终根据auc选出最好的模型。 分析步骤： 导入数据 数据清洗及准备 模型建立 模型评估 多模型对比 导入数据12345cs_training &lt;- read.csv(&quot;cs_training.csv&quot;)names(cs_training) a &lt;- cs_training a1 &lt;- cs_training colnames(a)&lt;-c(&apos;id&apos;,&apos;response&apos;,&apos;x1&apos;,&apos;age&apos;,&apos;x2&apos;,&apos;debtratio&apos;,&apos;monthlyincome&apos;,&apos;x3&apos;,&apos;x4&apos;,&apos;x5&apos;,&apos;x6&apos;,&apos;x7&apos;) 导入数据，并对列名重命名，方便分析。通过summary了解数据的整体情况，可以看到monthliincome和x7变量有缺失值 数据清洗123456789#age变量age&lt;-a$agevar_age&lt;-c(var=&quot;age&quot;,mean=mean(age,na.rm=TRUE),#na.rm=TRUE去除NA的影响median=median(age,na.rm=TRUE),quantile(age,c(0,0.01,0.1,0.25,0.5,0.75,0.9,0.99,1),na.rm=TRUE), max=max(age,na.rm=TRUE),missing=sum(is.na(age)) )View(var_age) var mean median 0 0.01 0.1 0.25 0.5 0.75 0.9 0.99 1 max missing age 52.2952066666667 52 0 24 33 41 52 63 72 87 109 109 0 这样可以看到各个变量的数据分布情况12# 查看异常值boxplot(age~response,data = a,horizontal = T ,frame = F , col = &quot;lightgray&quot;,main = &quot;Distribution&quot;) 上图可以看到，数据存在异常值。处理异常值：通常采用盖帽法，即用数据分布在1%的数据覆盖在1%以下的数据，用在99%的数据覆盖99%以上的数据。123456789101112block&lt;-function(x,lower=T,upper=T)&#123;if(lower)&#123;q1&lt;-quantile(x,0.01)x[x&lt;=q1]&lt;-q1&#125; if(upper)&#123;q99&lt;-quantile(x,0.99)x[x&gt;q99]&lt;-q99&#125;return(x)&#125;boxplot(age~response,data = a,horizontal = T ,frame = F , col = &quot;lightgray&quot;,main = &quot;Distribution&quot;) 经过处理，异常值大量减少12345678910# x1xa1&lt;-a$x1var_x1&lt;-c(var=&apos;xa1&apos;,mean=mean(xa1,na.rm = T),median=median(xa1,na.rm = T),quantile(xa1,c(0,0.01,0.1,0.5,0.75,0.9,0.99,1),na.rm = T), max=max(xa1,na.rm = T), miss=sum(is.na(xa1)) )boxplot(x1~response,data=a,horizontal=T, frame=F, col=&quot;lightgray&quot;,main=&quot;Distribution-x1&quot;) #对X1变量进行处理 a$x1&lt;-block(a$x1) 1234567891011121314151617181920212223242526272829303132333435363738# x2a$x2 summary(a$x2) xa2&lt;-a$x2 var_x2&lt;-c(var=&apos;xa2&apos;,mean=mean(xa2,na.rm = T), median=median(xa2,na.rm = T), quantile(xa2,c(0,0.01,0.1,0.5,0.75,0.9,0.99,1),na.rm = T), max=max(xa2,na.rm = T), miss=sum(is.na(xa2)) ) boxplot(x2~response,data=a,horizontal=T, frame=F, col=&quot;lightgray&quot;,main=&quot;Distribution&quot;) # 对x2变量进行处理 a$x2&lt;-block(a$x2) a$x1&lt;-round(a$x1,2)# debtratiosummary(a$debtratio) ratio&lt;-a$debtratio var_ratio&lt;-c(var=&apos;debtratio&apos;, mean=mean(ratio,na.rm = T), median=median(ratio,na.rm = T), quantile(ratio,c(0,0.01,0.1,0.5,0.75,0.9,0.99,1),na.rm = T), max=max(ratio,na.rm = T), miss=sum(is.na(ratio)) ) hist(a$debtratio)# 因为debtratio是百分比，对异常值的处理要结合实际a$debtratio&lt;-ifelse(a$debtratio&gt;1,1,a$debtratio)# monthlyincomeincome&lt;-a$monthlyincome var_income&lt;-c(var=&apos;income&apos;,mean=mean(income,na.rm = T), median=median(income,na.rm = T), quantile(income,c(0,0.01,0.1,0.5,0.75,0.9,0.99,1),na.rm = T),max=max(income,na.rm = T), miss=sum(is.na(income)) ) hist(income) boxplot(monthlyincome~response,data=a,horizontal=T, frame=F, col=&quot;lightgray&quot;,main=&quot;Distribution-x2&quot;)# 对缺失值处理a$monthlyincome&lt;-ifelse(is.na(a$monthlyincome)==T,6670.2,a$monthlyincome)# 对异常值处理a$monthlyincome&lt;-block(a$monthlyincome) 12345678910# x3summary(a$x3) x3&lt;-a$x3 var_x3&lt;-c(var=&apos;x3&apos;,mean=mean(x3,na.rm = T), median=median(x3,na.rm = T), quantile(x3,c(0,0.01,0.1,0.5,0.75,0.9,0.99,1),na.rm = T), max=max(x3,na.rm = T), miss=sum(is.na(x3)) ) names(a) # 对x3进行处理 a$x3&lt;-block(a$x3) 123456789# x4-延迟90天的次数summary(a$x4) x4&lt;-a$x4 var_x4&lt;-c(var=&apos;x4&apos;,mean=mean(x4,na.rm = T),median=median(x4,na.rm = T), quantile(x4,c(0,0.01,0.1,0.5,0.75,0.9,0.99,1),na.rm = T), max=max(x4,na.rm = T), miss=sum(is.na(x4)) ) # 对x4进行处理 a$x4&lt;-block(a$x4) 1234567891011# x5-贷款额度summary(a$x5) x5&lt;-a$x5 var_x5&lt;-c(var=&apos;x5&apos;,mean=mean(x5,na.rm = T), median=median(x5,na.rm = T), quantile(x5,c(0,0.01,0.1,0.5,0.75,0.9,0.99,1),na.rm = T), max=max(x5,na.rm = T), miss=sum(is.na(x5)) ) # 对x5异常值进行采用盖帽法处理 a$x5&lt;-block(a$x5) boxplot(a$x5) boxplot(x5~response , data = a , horizontal = T, main=&quot;Distribution-x5&quot;) 123456789# x6summary(a$x6) x6&lt;-a$x6 var_x6&lt;-c(var=&apos;x6&apos;,mean=mean(x6,na.rm = T), median=median(x6,na.rm = T), quantile(x6,c(0,0.01,0.1,0.5,0.75,0.9,0.99,1),na.rm = T), max=max(x6,na.rm = T), miss=sum(is.na(x6)) ) # 对x6进行盖帽法 a$x6&lt;-block(a$x6) 12345678910111213# x7summary(a$x7) x7&lt;-a$x7 var_x7&lt;-c(var=&apos;x7&apos;,mean=mean(x7,na.rm = T), median=median(x7,na.rm = T), quantile(x7,c(0,0.01,0.1,0.5,0.75,0.9,0.99,1),na.rm = T), max=max(x7,na.rm = T), miss=sum(is.na(x7)) ) hist(a$x7,freq=F)# 对缺失值处理a$x7&lt;-ifelse(is.na(a$x7)==T,0.76,a$x7)# 对异常值处理a$x7&lt;-block(a$x7) summary(a) 123#response变量# 为了方便理解，将1作为违约，0表示不违约a$response&lt;-as.numeric(!as.logical(a$response)) 建模数据分组1table(a$response) 0 1 10026 139974 数据正负比例不平衡，我们要对数据进行smote处理，smote算法的思想是合成新的少数类样本，合成的策略是对每个少数类样本a，从它的最近邻中随机选一个样本b，然后在a、b之间的连线上随机选一点作为新合成的少数类样本。 12345678910library(lattice) library(grid) library(DMwR) a$response &lt;- factor(a$response) a$response &lt;- as.factor(ifelse(a$response == 0 , &quot;yes&quot; , &quot;no&quot;)) newData &lt;- SMOTE(response ~ ., a) table(newData$response) newData$response &lt;- ifelse(newData$response == &quot;yes&quot; , 0 , 1) newData$response &lt;- as.numeric(newData$response) str(newData) 123456# 接下来进行分组index &lt;- sample(1:nrow(newData) , nrow(newData)*0.7) train &lt;- newData[index,] test &lt;- newData[-index,] table(train$response) table(test$response) table(train$response) 0 1 21213 27914 table(test$response) 0 1 8865 12190 逻辑回归建立模型123glm_model &lt;- glm(response~. , data = train , family = binomial()) summary(glm_model)#p值全部显著 使用逐步法剔除变量1step(glm_model , direction = &quot;both&quot;) VIF多重共线性检验123library(carData) library(car) vif(glm_model) #一般认为VIF值大于2的话，表明变量间存在共线性。此时没有大于2的值,各个变量间相互独立 预测12train_pred &lt;- predict(glm_model , newdata = train , type = &quot;response&quot;) test_pred &lt;- predict(glm_model , newdata = test , type = &quot;response&quot;) 模型评估（auc=0.842466）1234567library(gplots)library(ROCR)test_prob &lt;- prediction(test_pred, test$response) test_perf &lt;- performance(test_prob , &quot;tpr&quot; , &quot;fpr&quot;) test_auc &lt;- performance(test_prob ,&quot;auc&quot;)plot(test_perf) abline(a=0,b=1) cart决策树模型模型建立123456library(rpart) library(rpart.plot) library(RWeka) cart_dt&lt;-rpart.control(minsplit = 50,maxdepth = 4,xval=10,cp=0) cart_model &lt;- rpart(response~., data = train , method = &quot;anova&quot; , control = cart_dt) rpart.plot(cart_model,digits=3) 预测1test_pred &lt;- predict(cart_model , newdata = test) 模型评估（auc=0.3670627）12345test_prob &lt;- prediction(test_pred, test$response) test_perf &lt;- performance(test_prob , &quot;tpr&quot; , &quot;fpr&quot;) test_auc &lt;- performance(test_prob ,&quot;auc&quot;)plot(test_perf) abline(a=0,b=1) nnet包的单隐层BP网络对数据进行标准化1234#对数据进行标准化 names(train) train[,2:11] &lt;- scale(train[,2:11]) test[,2:11] &lt;- scale(test[,2:11]) 模型建立123library(nnet) train_nnet&lt;-nnet(response~., linout =F,size=10, decay=0.0076, maxit=200,data = train) # size隐节点数,decay权值衰减率 预测并将概率调整为0和11234test_pred&lt;-predict(train_nnet, test) test_pred[test_pred&lt;0.5]=0 test_pred[test_pred&gt;=0.5]=1 table(test_pred) test_pred 0 1 14523 6532 计算准确率1test_pred_rate&lt;-sum(test_pred==test$response)/length(test$response) 模型评估（auc=0.7848754）1234567library(gplots) library(ROCR) test_prob &lt;- prediction(test_pred, test$response) test_perf &lt;- performance(test_prob , &quot;tpr&quot; , &quot;fpr&quot;) test_auc &lt;- performance(test_prob ,&quot;auc&quot;)plot(test_perf) abline(a=0,b=1) 模型调参1234567891011121314151617181920212223242526272829303132333435363738394041##输入数据的预测变量必须是二分类的。且所有变量只包含模型输入输出变量。##调参时如果变量过多size不宜过大。##构建调参函数network()。 构建调参函数network()##构建调参函数network()。 network&lt;-function(formula,data,size,adjust,decay=0,maxit=200,scale=TRUE,samplerate=0.7,seed=1,linout=FALSE,ifplot=TRUE)&#123;library(nnet) ##规范输出变量为0,1 yvar&lt;-colnames(data)==(all.vars(formula)[1]) levels(data[,yvar])&lt;-c(0,1) ##抽样建立训练集和测试集 set.seed(seed) select&lt;-sample(1:nrow(data),nrow(data)*samplerate) train=data[select,] test=data[-select,] ##根据给定判断进行标准化 if(scale==T)&#123; xvar&lt;-colnames(data)!=(all.vars(formula)[1]) train[,xvar]=scale(train[,xvar]) test[,xvar]=scale(test[,xvar]) &#125; ##循环使用nnet训练调参 obj&lt;-eval(parse(text = adjust)) auc&lt;-data.frame() for(i in obj)&#123; if(adjust==&quot;size&quot;)&#123; mynnet&lt;-nnet(formula,size=i,linout=linout,decay=decay, maxit=maxit,trace=FALSE,data=train) &#125; else if(adjust==&quot;decay&quot;)&#123; mynnet&lt;-nnet(formula,size=size,linout=linout,decay=i, maxit=maxit,trace=FALSE,data=train)&#125; ##调用之前的ROC()得到对应参数的AUC值 objcolname&lt;-all.vars(formula)[1] auc0&lt;-ROC(model=mynnet,train=train,test=test, objcolname=objcolname,ifplot=F) ##输出指定参数不同值对应的数据框 out&lt;-data.frame(i,auc0) auc&lt;-rbind(auc,out) &#125; names(auc)&lt;-c(adjust,&quot;Train_auc&quot;,&quot;Test_auc&quot;) if(ifplot==T)&#123; library(plotrix) twoord.plot(auc[,1],auc$Train_auc,auc[,1],auc$Test_auc,lcol=4,rcol=2,xlab=adjust,ylab=&quot;Train_auc&quot;, rylab=&quot;Test_auc&quot;,type=c(&quot;l&quot;,&quot;b&quot;),lab=c(15,5,10)) &#125; return(auc) &#125; auc&lt;-network(response~.,data=train,size=4:16,adjust=&quot;size&quot;, decay=0.0001,maxit=200,scale=T) #发现当隐藏节点数为6的时候，auc最高 auc&lt;-network(response~.,data=train,size=11,adjust=&quot;decay&quot;, decay=c(0,seq(0.0001,0.01,0.0003)),maxit=200) #发现decay等于0.0025的时候， auc最高 建模2.0123#调参后的模型 #size =11 , decay = 0.0013 , maxit = 200 library(nnet) train_nnet &lt;- nnet(response~. , linout = F , size = 4 , decay = 0.0031 , maxit = 200 , data = train) 模型评估（auc = 0.7923195）123456789101112# 预测为0，1 test_pred&lt;-predict(train_nnet, test) test_pred[test_pred&lt;0.5]=0 test_pred[test_pred&gt;=0.5]=1 table(test_pred) #计算准确率 test_pred_rate&lt;-sum(test_pred==test$response)/length(test$response) # 模型评估 library(gplots) library(ROCR) test_prob &lt;- prediction(test_pred, test$response) test_perf &lt;- performance(test_prob , &quot;tpr&quot; , &quot;fpr&quot;) test_auc &lt;- performance(test_prob ,&quot;auc&quot;)plot(test_perf)abline(a=0,b=1) xgboost算法模型建立12345library(xgboost) xgb_model &lt;- xgboost(data = data.matrix(train[,-1]) , label=data.matrix(train$response) , max_depth = 6, eta= 0.3 , nthread = 2 , nrounds = 15 , objective = &quot;binary:logistic&quot; , seed = 123) 预测1test_prob &lt;- predict(xgb_model , data.matrix(test[,-1])) 模型评估（auc = 0.860617）12345test_pred &lt;- prediction(test_prob , test$response) test_perf &lt;- performance(test_pred , &quot;tpr&quot; , &quot;fpr&quot;) test_auc &lt;- performance(test_pred , &quot;auc&quot;)plot(test_perf)abline(a=0,b=1) 随机森林模型建立123library(randomForest) random_model &lt;- randomForest(response~. , data = train) random_model 模型预测1test_prob &lt;- predict(random_model , test , type= &quot;response&quot;) 模型评估（auc = 0.8531173）12345test_pred &lt;- prediction(test_prob , test$response) test_perf &lt;- performance(test_pred , &quot;tpr&quot; , &quot;fpr&quot;) test_auc &lt;- performance(test_pred , &quot;auc&quot;)plot(test_perf)abline(a=0,b=1) 综上，通过多种模型对比可以看到xgboost算法的模型精确度是最高的达到0.860617。]]></content>
      <categories>
        <category>R</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>kaggle</tag>
        <tag>glm</tag>
        <tag>step</tag>
        <tag>vif</tag>
        <tag>cart</tag>
        <tag>nnet</tag>
        <tag>xgboost</tag>
        <tag>randomForest</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于R语言的自动数据收集，网络抓取和文本挖掘指南]]></title>
    <url>%2F2018%2F10%2F02%2F%E5%9F%BA%E4%BA%8ER%E8%AF%AD%E8%A8%80%E7%9A%84%E8%87%AA%E5%8A%A8%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%EF%BC%8C%E7%BD%91%E7%BB%9C%E6%8A%93%E5%8F%96%E5%92%8C%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[书籍官方网址r-datacollection.com 配套代码源代码https://github.com/pangjinfeng/Wiley-ADCR]]></content>
      <categories>
        <category>R</category>
        <category>Others</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>文本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一款有趣的IDE—RCode]]></title>
    <url>%2F2018%2F10%2F01%2F%E4%B8%80%E6%AC%BE%E6%9C%89%E8%B6%A3%E7%9A%84IDE%E2%80%94RCode%2F</url>
    <content type="text"><![CDATA[RCode Directly edit your variablesSimple variables, lists, data frames… Inspect and edit everything. Modern autocompletionAnalyse all your scripts to get the perfect autocompletion. Fast graphsQuickly visualize your data with a time series or a density graph. Command history reinventedExecution time for each command, and displayed in red if an error occurs. And more…]]></content>
      <categories>
        <category>R</category>
      </categories>
      <tags>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[R语言自定义词云 wordcloud]]></title>
    <url>%2F2018%2F09%2F30%2FR%E8%AF%AD%E8%A8%80%E8%87%AA%E5%AE%9A%E4%B9%89%E8%AF%8D%E4%BA%91%2F</url>
    <content type="text"><![CDATA[wordcloud2 {wordcloud2} R DocumentationCreate wordcloud by wordcloud2.jsDescriptionFunction for Creating wordcloud by wordcloud2.js Usage123456wordcloud2(data, size = 1, minSize = 0, gridSize = 0, fontFamily = &apos;Segoe UI&apos;, fontWeight = &apos;bold&apos;, color = &apos;random-dark&apos;, backgroundColor = &quot;white&quot;, minRotation = -pi/4, maxRotation = pi/4, shuffle = TRUE, rotateRatio = 0.4, shape = &apos;circle&apos;, ellipticity = 0.65, widgetsize = NULL, figPath = NULL, hoverFunction = NULL) Arguments data A data frame including word and freq in each column size Font size, default is 1. The larger size means the bigger word. minSize A character string of the subtitle gridSize Size of the grid in pixels for marking the availability of the canvas the larger the grid size, the bigger the gap between words. fontFamily Font to use. fontWeight Font weight to use, e.g. normal, bold or 600 color color of the text, keyword ‘random-dark’ and ‘random-light’ can be used. color vector is also supported in this param backgroundColor Color of the background. minRotation If the word should rotate, the minimum rotation (in rad) the text should rotate. maxRotation If the word should rotate, the maximum rotation (in rad) the text should rotate. Set the two value equal to keep all text in one angle. shuffle Shuffle the points to draw so the result will be different each time for the same list and settings. rotateRatio Probability for the word to rotate. Set the number to 1 to always rotate. shape The shape of the “cloud” to draw. Can be a keyword present. Available presents are ‘circle’ (default), ‘cardioid’ (apple or heart shape curve, the most known polar equation), ‘diamond’ (alias of square), ‘triangle-forward’, ‘triangle’, ‘pentagon’, and ‘star’. ellipticity degree of “flatness” of the shape wordcloud2.js should draw. widgetsize size of the widgets figPath The path to a figure used as a mask. hoverFunction Callback to call when the cursor enters or leaves a region occupied by a word. A string of java script function. Exampleslibrary(wordcloud2)12345678910111213141516171819202122232425262728293031# Global variables can go herewordcloud2(demoFreq)wordcloud2(demoFreq, size = 2)wordcloud2(demoFreq, size = 1,shape = &apos;pentagon&apos;)wordcloud2(demoFreq, size = 1,shape = &apos;star&apos;)wordcloud2(demoFreq, size = 2, color = &quot;random-light&quot;, backgroundColor = &quot;grey&quot;)wordcloud2(demoFreq, size = 2, minRotation = -pi/2, maxRotation = -pi/2)wordcloud2(demoFreq, size = 2, minRotation = -pi/6, maxRotation = -pi/6, rotateRatio = 1)wordcloud2(demoFreq, size = 2, minRotation = -pi/6, maxRotation = pi/6, rotateRatio = 0.9)wordcloud2(demoFreqC, size = 2, color = &quot;random-light&quot;, backgroundColor = &quot;grey&quot;)wordcloud2(demoFreqC, size = 2, minRotation = -pi/6, maxRotation = -pi/6, rotateRatio = 1)# Color VectorcolorVec = rep(c(&apos;red&apos;, &apos;skyblue&apos;), length.out=nrow(demoFreq))wordcloud2(demoFreq, color = colorVec, fontWeight = &quot;bold&quot;)wordcloud2(demoFreq, color = ifelse(demoFreq[, 2] &gt; 20, &apos;red&apos;, &apos;skyblue&apos;)) 这个包里面包含了两个数据集，demoFreqC 和 demoFreq，前者是一些中文数据，后者是一些英文数据。这两个数据都包含了两个变量，一个是文本，另一个是文本的数量。1234567891011wordcloud2(data, size = 1, minSize = 0, gridSize = 0,fontFamily = &apos;Segoe UI&apos;,fontWeight = &apos;bold&apos;,color = &apos;random-dark&apos;, backgroundColor = &quot;white&quot;,minRotation = -pi/4, maxRotation = pi/4, shuffle = TRUE,rotateRatio = 0.4, shape = &apos;circle&apos;,ellipticity = 0.65, widgetsize = NULL, figPath = NULL, hoverFunction = NULL) wordcloud2提供了基本的词云功能，letterCloud可以使用选定的词绘制词云，这个词可以是英文，也可以是中文。上面就是wordcloud2（）函数，里面参数一大堆，但在一般情况下，我们却用不了那么多。其中data就是我们要处理的数据。shape参数可以选择词云的形状，有上面代码可知它默认为圆形（circle），它还提供了其他一些参数，cardioid(心形)，star(星形)，diamond（钻石形），triangle-forward（三角形），triangle（三角形），这两个三角形就是倾斜方向不同而已，pentagon(五边形)；size参数为字体的大小；backgroundColor设置背景颜色，默认为白色，但有的时候黑色效果更好，颜色更能凸显出来。1wordcloud2(demoFreq) 1wordcloud2(demoFreq, size = 1,shape=&apos;star&apos;) 12example &lt; -system.file(&quot;examples.png&quot;,package=&quot;wordcloud2&quot;)wordcloud2(demoFreqC, size = 1, figPath = lexample)]]></content>
      <categories>
        <category>R</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>wordcloud2</tag>
        <tag>词云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google 镜像导航]]></title>
    <url>%2F2018%2F09%2F28%2FGoogle-%E9%95%9C%E5%83%8F%2F</url>
    <content type="text"><![CDATA[Google 镜像导航http://ac.scmor.com/]]></content>
      <categories>
        <category>Others</category>
      </categories>
      <tags>
        <tag>Google</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Color Hunt]]></title>
    <url>%2F2018%2F09%2F26%2FColor-Hunt%2F</url>
    <content type="text"><![CDATA[Color Hunt is a free and open platform for color inspiration with thousands of trendy hand-picked color palettes colorhunt 虽为设计师而生，但也不妨作为一个令可视化图表更为好看的配色网站 colorhunt.co]]></content>
      <categories>
        <category>Others</category>
      </categories>
      <tags>
        <tag>可视化</tag>
        <tag>color</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL 教程]]></title>
    <url>%2F2018%2F09%2F25%2FSQL-%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[关于 W3SchoolW3School 是因特网上最大的 WEB 开发者资源W3School 是完全免费的W3School 是非盈利性的W3School 一直在升级和更新W3School 是 W3C 中国社区成员，致力于推广 W3C 标准技术 SQL教程]]></content>
      <categories>
        <category>SQL</category>
      </categories>
      <tags>
        <tag>W3chool</tag>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[R语言进行词云分析 jiebaR、wordcloud]]></title>
    <url>%2F2018%2F09%2F25%2F%E5%88%A9%E7%94%A8R%E8%AF%AD%E8%A8%80%E8%BF%9B%E8%A1%8C%E8%AF%8D%E4%BA%91%E5%88%86%E6%9E%90-jiebaR%E3%80%81wordcloud%2F</url>
    <content type="text"><![CDATA[jiebaRjiebaR是一款高效的R语言中文分词包，底层使用的是C++，通过Rcpp进行调用很高效。jieba分词基于MIT协议,让R的可以方便的处理中文文本。jieba中文分词的R语言版本，支持最大概率法（Maximum Probability）, 隐式马尔科夫模型（Hidden Markov Model）, 索引模型（QuerySegment）, 混合模型（MixSegment）, 共四种分词模式， 同时有词性标注，关键词提取，文本Simhash相似度比较等功能。项目使用了Rcpp和CppJieba进行开发。 WordcloudWordcloud包在做词语分析时并没有多大的作用，但是在后期的报告展示中却起着很大的作用。虽然说实质大于形式，在实质能够保证的前提下，一个好的形式是成功的关键点所在。Wordcloud包就是一个可以使词频以图形的形式展示的软件包，它可以通过改变词云的形状和颜色，是的分析结果锦上添花。 word.txt1234567891011121314library(jiebaRD)library(jiebaR)library(wordcloud)#读入数据分隔符是‘\n’，字符编码是‘UTF-8’，what=&apos;&apos;表示以字符串类型读入word &lt;- scan(&apos;C:\\Users\\10568\\Desktop\\word.txt&apos;,sep=&apos;\n&apos;,what=&apos;&apos;,encoding=&quot;GBK&quot;)seg &lt;- qseg[word] #使用qseg类型分词，并把结果保存到对象seg中seg &lt;- table(seg) #统计词频length(seg) #查看处理完后剩余的词数seg &lt;- sort(seg, decreasing = TRUE)[1:100] #降序排序，并提取出现次数最多的前100个词语data=data.frame(seg)wordcloud(data$seg , data$Freq, colors = rainbow(100), random.order=F)x11()dev.off()]]></content>
      <categories>
        <category>R</category>
      </categories>
      <tags>
        <tag>词云</tag>
        <tag>jiebaR</tag>
        <tag>Wordcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[序贯设计及其应用]]></title>
    <url>%2F2018%2F09%2F23%2F%E5%BA%8F%E8%B4%AF%E8%AE%BE%E8%AE%A1%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[1、 单因素优选法设x为试验中最重要的因素或唯一的因素，并设其包含响应y的最优响应点的范围为 [a,b] .将响应y与因素x之间的关系写成数学表达式，不能写出表达式时，就要确定评估结果好坏的方法。令目标函数y=f(x)中不存在随机误差的情形。黄金分割法：第一个试验点x_1设在范围 [a,b] 的0.618位置上，第二个试验点x_2取成x_1的对称点，即 用f(x_1)和f(x_2)分别表示x_1和x_2处的响应值.此时分为以下两种情形：情形1：若f(x_1)比f(x_2)好，即x_1是好点，于是把试验区域[a, x_2)划去，剩下[x_2,b].情形2：若f(x_1)比f(x_2)差，即x_2是好点，于是把试验区域（x_1,b]划去，剩下[a, x_1]. 2、 响应曲面法2.1、 最陡上升法最陡上升法是一种使响应y朝最陡上升的方向序贯移动的方法.显然，若试验目的是使y最小化，那么该方法就变成了最陡下降法.当前试验点x的领域内的一些试验的数据，由最小二乘法得出拟合模型…… 原文太多数学公式了，markdown 编辑太麻烦，直接上传源文件算了, 等哪天找到 word 转 markdown ，数学公式不乱码再更新…… 源文件点击下载]]></content>
      <categories>
        <category>试验设计</category>
      </categories>
      <tags>
        <tag>Matlab</tag>
        <tag>R</tag>
        <tag>单因素优选法</tag>
        <tag>响应曲面法</tag>
        <tag>最陡上升法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[火山图 lattice]]></title>
    <url>%2F2018%2F09%2F23%2F%E7%81%AB%E5%B1%B1%E5%9B%BE-lattice%2F</url>
    <content type="text"><![CDATA[123456install.packages(&quot;lattice&quot;)library(lattice)head(volcano)contourplot(volcano) # 绘制火山的三维等高线图levelplot(volcano) # 绘制火山的三维水平图wireframe(volcano) # 绘制火山的三维线框图]]></content>
      <categories>
        <category>R</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>lattice</tag>
        <tag>火山图</tag>
        <tag>三维等高线图</tag>
        <tag>三维水平图</tag>
        <tag>三维线框图</tag>
        <tag>volcano</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络图 igraph]]></title>
    <url>%2F2018%2F09%2F23%2F%E7%BD%91%E7%BB%9C%E5%9B%BE-igraph%2F</url>
    <content type="text"><![CDATA[12345install.packages(&quot;igraph&quot;)library(igraph)data=matrix(sample(0:1, 400, replace=TRUE, prob=c(0.8,0.2)), nrow=20)network=graph_from_adjacency_matrix(data , mode=&apos;undirected&apos;, diag=F )plot(network, layout=layout.sphere)]]></content>
      <categories>
        <category>R</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>igragh</tag>
        <tag>matrix</tag>
        <tag>sample</tag>
        <tag>layout</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二维直方图 hexbin]]></title>
    <url>%2F2018%2F09%2F23%2F%E4%BA%8C%E7%BB%B4%E7%9B%B4%E6%96%B9%E5%9B%BE-hexbin%2F</url>
    <content type="text"><![CDATA[123456789install.packages(&quot;hexbin&quot;)install.packages(&quot;RColorBrewer&quot;)library(hexbin)library(RColorBrewer)x &lt;- rnorm(mean=1.5, 5000)y &lt;- rnorm(mean=1.6, 5000)bin&lt;-hexbin(x, y, xbins=40)my_colors=colorRampPalette(rev(brewer.pal(11,&apos;Spectral&apos;)))plot(bin, colramp=my_colors, legend=F)]]></content>
      <categories>
        <category>R</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>hexbin</tag>
        <tag>RColorBrewer</tag>
        <tag>colorRampalette</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[时间序列分析 forecast]]></title>
    <url>%2F2018%2F09%2F23%2F%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%88%86%E6%9E%90-forecast%2F</url>
    <content type="text"><![CDATA[12345678install.packages(&quot;forecast&quot;)library(forecast)# 使用英国每月死于肺病的人数数据fit&lt;- auto.arima(mdeaths)# 设置置信区间forecast(fit, level=c(80, 95, 99), h=3)# 绘制时间序列趋势图plot(forecast(fit), shadecols=&quot;oldstyle&quot;)]]></content>
      <categories>
        <category>R</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>时间序列</tag>
        <tag>forecast</tag>
        <tag>auto.arima</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[相关性系数矩阵（椭圆） ellipse]]></title>
    <url>%2F2018%2F09%2F23%2F%E7%9B%B8%E5%85%B3%E6%80%A7%E7%B3%BB%E6%95%B0%E7%9F%A9%E9%98%B5%EF%BC%88%E6%A4%AD%E5%9C%86%EF%BC%89-ellipse%2F</url>
    <content type="text"><![CDATA[12345install.packages(&quot;ellipse&quot;)library(ellipse)data(mtcars)fit &lt;- lm(mpg ~ ., mtcars)plotcorr(summary(fit, correlation = TRUE)$correlation)]]></content>
      <categories>
        <category>R</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>相关系数矩阵</tag>
        <tag>ellipse</tag>
        <tag>mtcars</tag>
        <tag>lm</tag>
        <tag>summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[时间序列数据的可视化 dygraphs]]></title>
    <url>%2F2018%2F09%2F23%2F%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96-dygraphs%2F</url>
    <content type="text"><![CDATA[12345install.packages(&quot;dygraphs&quot;)library(dygraphs)data=data.frame( time=c( seq(0,20,0.5), 40), value=runif(42))str(data)dygraph(data)]]></content>
      <categories>
        <category>R</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>时间序列</tag>
        <tag>dygraphs</tag>
        <tag>runif</tag>
        <tag>str</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[相关系数矩阵 corrgram]]></title>
    <url>%2F2018%2F09%2F23%2F%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0%E7%9F%A9%E9%98%B5-corrplot%2F</url>
    <content type="text"><![CDATA[123456789install.packages(corrgram)library(corrgram)library(mtcarData)library(mtcar)corrgram(mtcars, order=TRUE, lower.panel=panel.ellipse, upper.panel=panel.pts, text.panel=panel.txt, diag.panel=panel.minmax, main=&quot;Corrgram of mtcars data using scatter plots and ellipses&quot;) 123456cols &lt;- colorRampPalette(c(&quot;darkgoldenrod4&quot;, &quot;burlywood1&quot;, &quot;darkkhaki&quot;, &quot;darkgreen&quot;))corrgram(mtcars, order=TRUE, col.regions=cols, lower.panel=panel.shade, upper.panel=panel.conf, text.panel=panel.txt, main=&quot;A Corrgram (or Horse) of a Different Color&quot;)]]></content>
      <categories>
        <category>R</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>corrgram</tag>
        <tag>order</tag>
        <tag>相关</tag>
        <tag>mtcar</tag>
        <tag>mtcarData</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[theme: next 相关配置优化]]></title>
    <url>%2F2018%2F09%2F22%2Ftheme-next-%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[作者：Alvabill链接：https://www.jianshu.com/p/1f8107a8778c来源：简书]]></content>
      <categories>
        <category>themes</category>
      </categories>
      <tags>
        <tag>next</tag>
        <tag>theme</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[相关系数矩阵 corrgram]]></title>
    <url>%2F2018%2F09%2F21%2F%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0%E7%9F%A9%E9%98%B5-corrgram%2F</url>
    <content type="text"><![CDATA[123456789101112install.packages(&quot;iterators&quot;)install.packages(&quot;corrgram&quot;)install.packages(&quot;kernlab&quot;)library(iterators)library(kernlab)library(corrgram)corrgram(mtcars, order=TRUE, lower.panel=panel.shade, upper.panel=panel.pie, text.panel=panel.txt, main=&quot;Correlogram of mtcar intercorrelations&quot;)]]></content>
      <categories>
        <category>R</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>相关系数矩阵</tag>
        <tag>corrgram</tag>
        <tag>iterators</tag>
        <tag>kernlab</tag>
        <tag>order</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[哈夫曼图 CMplot]]></title>
    <url>%2F2018%2F09%2F21%2F%E5%93%88%E5%A4%AB%E6%9B%BC%E5%9B%BE-CMplot%2F</url>
    <content type="text"><![CDATA[12345678910install.packages(&quot;CMplot&quot;)library(&quot;CMplot&quot;)data(pig60K) CMplot(pig60K[sample(1:nrow(pig60K),10000),c(1:4)],plot.type=&quot;c&quot;,threshold=c(0.01,0.05)/nrow(pig60K),threshold.col=c(&apos;red&apos;,&apos;orange&apos;),multracks=FALSE, chr.den.col=NULL, file.output = F)]]></content>
      <categories>
        <category>R</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>CMplot</tag>
        <tag>哈夫曼图</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Markdown编辑数学公式]]></title>
    <url>%2F2018%2F09%2F20%2F%E4%BD%BF%E7%94%A8Markdown%E7%BC%96%E8%BE%91%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Cmd Markdown 公式指导手册 在线使用 LaTex 进行编辑]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
        <tag>LaTex</tag>
        <tag>数学公式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据归一化与标准化]]></title>
    <url>%2F2018%2F09%2F18%2F%E6%95%B0%E6%8D%AE%E5%BD%92%E4%B8%80%E5%8C%96%E4%B8%8E%E6%A0%87%E5%87%86%E5%8C%96%2F</url>
    <content type="text"><![CDATA[归一化（Normalization）为了将数据映射到0~1之间，去掉量纲的过程，让计算更加合理，不会因为量纲问题导致1米与100mm产生不同。 标准化（Standardization）消除分布产生的度量偏差，例如：班级数学考试，数学成绩在90-100之间，语文成绩在60-100之间，那么，小明数学90，语文100，小花数学95，语文95，如何评价两个综合成绩好坏的数学处理方式。 R语言处理函数scale(dt,center = T,scale = T)scale方法中的两个参数center和scale的解释：1.center和scale默认为真,即T或者TRUE2.center为真表示数据中心化(只减去均值不做其他处理)3.scale为真表示数据标准化]]></content>
      <categories>
        <category>R</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>归一化</tag>
        <tag>标准化</tag>
        <tag>scale</tag>
        <tag>预处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DataGirls Visual Vocabulary]]></title>
    <url>%2F2018%2F09%2F17%2FataGirls-Visual-Vocabulary%2F</url>
    <content type="text"><![CDATA[收藏 Tableau 报表DataGirls Visual Vocabulary.twbx]]></content>
      <categories>
        <category>Tableau</category>
      </categories>
      <tags>
        <tag>Tableau</tag>
        <tag>报表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Power BI 的咖啡销售报表]]></title>
    <url>%2F2018%2F09%2F16%2F%E5%9F%BA%E4%BA%8EPower-BI-%E7%9A%84%E5%92%96%E5%95%A1%E9%94%80%E5%94%AE%E6%8A%A5%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[使用数据 coffee 国家 1999/1/1 0:00:00 2000/1/1 0:00:00 2001/1/1 0:00:00 2002/1/1 0:00:00 2003/1/1 0:00:00 2004/1/1 0:00:00 2005/1/1 0:00:00 2006/1/1 0:00:00 马来西亚 29011 74405 116276 28958 35278 68289 33988 34629 韩国 32361 43192 68662 24125 37215 58806 85743 43024 泰国 78318 18631 121685 118535 84856 324123 102330 12768 日本 74003 17720 17981 62771 19747 110761 45985 24638 新西兰 21777 92099 62920 89419 78395 47050 41368 51758 澳大利亚 36868 112761 118956 105545 55199 108308 22727 73018 新加坡 10548 47598 88790 16378 74768 106765 32942 42573 巴基斯坦 64683 20131 114330 80276 20992 24810 40699 121076 中国 109764 55304 121865 14442 41610 21369 19328 51958 菲律宾 89140 99648 57413 123987 105914 33659 89062 121135 印度 104759 80649 60982 34981 22973 56098 87989 90123 缅甸 12684 78595 74413 112562 25204 88855 72764 55347 印度尼西亚 73957 74223 42882 13225 121958 91761 57875 77818 coffee.pbix]]></content>
      <categories>
        <category>Power BI</category>
      </categories>
      <tags>
        <tag>Power BI</tag>
        <tag>报表</tag>
        <tag>销售</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[theme：next]]></title>
    <url>%2F2018%2F09%2F15%2Ftheme%EF%BC%9Anext%2F</url>
    <content type="text"><![CDATA[今天新换的一个找了很久的主题，内附详细安装以及配置过程theme：next]]></content>
      <categories>
        <category>themes</category>
      </categories>
      <tags>
        <tag>theme</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Matlab三维图形增加图层]]></title>
    <url>%2F2018%2F09%2F15%2FMatlab%E4%B8%89%E7%BB%B4%E5%9B%BE%E5%BD%A2%E5%A2%9E%E5%8A%A0%E5%9B%BE%E5%B1%82%2F</url>
    <content type="text"><![CDATA[%% 圆柱R=0.1;h=1.7;m=100;[x,y,z]=cylinder(R,m);%创建以(0,0)为圆心，高度为[0,1]，半径为R的圆柱% z = z*h %高度为hmeshz(x,y,z) %% 增加两条直线 （增加图层方法一致）hold onx1 = [-0.11,-0.11];x2 = [-0.12,-0.17];y = [0.1,0.1];z = [0,1.7];plot3(x1,y,z);plot3(x2,y,z);hold off%%]]></content>
      <categories>
        <category>Matlab</category>
      </categories>
      <tags>
        <tag>Matlab</tag>
        <tag>圆柱</tag>
        <tag>图层</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于 Power BI 的商品销售可视化]]></title>
    <url>%2F2018%2F09%2F11%2F%E4%BA%8E-Power-BI-%E7%9A%84%E5%95%86%E5%93%81%E9%94%80%E5%94%AE%E5%8F%AF%E8%A7%86%E5%8C%96%2F</url>
    <content type="text"><![CDATA[shop.pbix原数据 shop.csv]]></content>
      <categories>
        <category>Power BI</category>
      </categories>
      <tags>
        <tag>Power BI</tag>
        <tag>商品销售</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Power BI Top 10 cost of living state]]></title>
    <url>%2F2018%2F09%2F09%2FPower-BI-Top-10-cost-of-living-state%2F</url>
    <content type="text"><![CDATA[Power BI top10]]></content>
      <categories>
        <category>Power BI</category>
      </categories>
      <tags>
        <tag>Power BI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于SPSS的相关分析、方差分析、回归分析]]></title>
    <url>%2F2018%2F09%2F02%2F%E5%9F%BA%E4%BA%8ESPSS%E7%9A%84%E7%9B%B8%E5%85%B3%E5%88%86%E6%9E%90%E3%80%81%E6%96%B9%E5%B7%AE%E5%88%86%E6%9E%90%E3%80%81%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90-1%2F</url>
    <content type="text"><![CDATA[数据来源mtcars {datasets} R Documentation Motor Trend Car Road Tests The data was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973–74 models). Format A data frame with 32 observations on 11 variables.1234567891011[, 1] mpg Miles/(US) gallon[, 2] cyl Number of cylinders[, 3] disp Displacement (cu.in.)[, 4] hp Gross horsepower[, 5] drat Rear axle ratio[, 6] wt Weight (1000 lbs)[, 7] qsec 1/4 mile time[, 8] vs V/S[, 9] am Transmission (0 = automatic, 1 = manual)[,10] gear Number of forward gears[,11] carb Number of carburetors mpg cyl disp hp drat wt qsec vs am gear carb Mazda RX4 21 6 160 110 3.9 2.62 16.46 V-Engine Manual 4 4 Mazda RX4 Wag 21 6 160 110 3.9 2.875 17.02 V-Engine Manual 4 4 Datsun 710 22.8 4 108 93 3.85 2.32 18.61 Straight Engine Manual 4 1 Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 Straight Engine Automatic 3 1 Hornet Sportabout 18.7 8 360 175 3.15 3.44 17.02 V-Engine Automatic 3 2 Valiant 18.1 6 225 105 2.76 3.46 20.22 Straight Engine Automatic 3 1 Duster 360 14.3 8 360 245 3.21 3.57 15.84 V-Engine Automatic 3 4 Merc 240D 24.4 4 146.7 62 3.69 3.19 20 Straight Engine Automatic 4 2 Merc 230 22.8 4 140.8 95 3.92 3.15 22.9 Straight Engine Automatic 4 2 Merc 280 19.2 6 167.6 123 3.92 3.44 18.3 Straight Engine Automatic 4 4 Merc 280C 17.8 6 167.6 123 3.92 3.44 18.9 Straight Engine Automatic 4 4 Merc 450SE 16.4 8 275.8 180 3.07 4.07 17.4 V-Engine Automatic 3 3 Merc 450SL 17.3 8 275.8 180 3.07 3.73 17.6 V-Engine Automatic 3 3 Merc 450SLC 15.2 8 275.8 180 3.07 3.78 18 V-Engine Automatic 3 3 Cadillac Fleetwood 10.4 8 472 205 2.93 5.25 17.98 V-Engine Automatic 3 4 Lincoln Continental 10.4 8 460 215 3 5.424 17.82 V-Engine Automatic 3 4 Chrysler Imperial 14.7 8 440 230 3.23 5.345 17.42 V-Engine Automatic 3 4 Fiat 128 32.4 4 78.7 66 4.08 2.2 19.47 Straight Engine Manual 4 1 Honda Civic 30.4 4 75.7 52 4.93 1.615 18.52 Straight Engine Manual 4 2 Toyota Corolla 33.9 4 71.1 65 4.22 1.835 19.9 Straight Engine Manual 4 1 Toyota Corona 21.5 4 120.1 97 3.7 2.465 20.01 Straight Engine Automatic 3 1 Dodge Challenger 15.5 8 318 150 2.76 3.52 16.87 V-Engine Automatic 3 2 AMC Javelin 15.2 8 304 150 3.15 3.435 17.3 V-Engine Automatic 3 2 Camaro Z28 13.3 8 350 245 3.73 3.84 15.41 V-Engine Automatic 3 4 Pontiac Firebird 19.2 8 400 175 3.08 3.845 17.05 V-Engine Automatic 3 2 Fiat X1-9 27.3 4 79 66 4.08 1.935 18.9 Straight Engine Manual 4 1 Porsche 914-2 26 4 120.3 91 4.43 2.14 16.7 V-Engine Manual 5 2 Lotus Europa 30.4 4 95.1 113 3.77 1.513 16.9 Straight Engine Manual 5 2 Ford Pantera L 15.8 8 351 264 4.22 3.17 14.5 V-Engine Manual 5 4 Ferrari Dino 19.7 6 145 175 3.62 2.77 15.5 V-Engine Manual 5 6 Maserati Bora 15 8 301 335 3.54 3.57 14.6 V-Engine Manual 5 8 Volvo 142E 21.4 4 121 109 4.11 2.78 18.6 Straight Engine Manual 4 2 相关分析 (mpg~wr+qsec) Correlations相关性 mpg wt qsec disp hp drat mpg Pearson 相关性 1 -.868** .419* -.848** -.776** .681** 显著性（双侧） 0 0.017 0 0 0 N 32 32 32 32 32 32 wt Pearson 相关性 -.868** 1 -0.175 .888** .659** -.712** 显著性（双侧） 0 0.339 0 0 0 N 32 32 32 32 32 32 qsec Pearson 相关性 .419* -0.175 1 -.434* -.708** 0.091 显著性（双侧） 0.017 0.339 0.013 0 0.62 N 32 32 32 32 32 32 disp Pearson 相关性 -.848** .888** -.434* 1 .791** -.710** 显著性（双侧） 0 0 0.013 0 0 N 32 32 32 32 32 32 hp Pearson 相关性 -.776** .659** -.708** .791** 1 -.449** 显著性（双侧） 0 0 0 0 0.01 N 32 32 32 32 32 32 drat Pearson 相关性 .681** -.712** 0.091 -.710** -.449** 1 显著性（双侧） 0 0 0.62 0 0.01 N 32 32 32 32 32 32 **. 在 .01 水平（双侧）上显著相关。 *. 在 0.05 水平（双侧）上显著相关。 在0.01水平上： mpg与 wt、qsec、disp、hp、drat 相关性显著；wt 与 mpg、disp、hp、drat相关性显著；sqec 与 mpg、disp、hp、drat 相关性显著；disp 与 mpg、wt、qsec、hp、drat 相关性显著；hp 与 mpg、wt、qsec、disp、drat 相干性显著；drat 与 mpg、wt、qsec、disp、hp 相关性显著； 单因素方差分析（cyl~mpg）Oneway 描述 mpg N 均值 标准差 标准误 均值的 95% 置信区间 极小值 下限 上限 4 11 26.664 4.5098 1.3598 23.634 29.693 21.4 6 7 19.743 1.4536 0.5494 18.399 21.087 17.8 8 14 15.1 2.56 0.6842 13.622 16.578 10.4 总数 32 20.091 6.0269 1.0654 17.918 22.264 10.4 方差齐性检验 mpg Levene 统计量 df1 df2 显著性 6.484 2 29 0.005 单因素方差分析 mpg 平方和 df 均方 F 显著性 组间 824.785 2 412.392 39.698 .000 组内 301.263 29 10.388 总数 1126.047 31 由于Levene检验没有证据说明三种 cyl 的方差相等，参照两种不同的两两比较的结果是必要的。 Post Hoc Tests 多重比较 因变量: mpg (I) cyl (J) cyl 均值差 (I-J) 标准误 显著性 95% 置信区间 下限 上限 Bonferroni 4 6 6.9208* 1.5583 0 2.961 10.88 8 11.5636* 1.2986 0 8.264 14.863 6 4 -6.9208* 1.5583 0 -10.88 -2.961 8 4.6429* 1.492 0.012 0.852 8.434 8 4 -11.5636* 1.2986 0 -14.863 -8.264 6 -4.6429* 1.492 0.012 -8.434 -0.852 Tamhane 4 6 6.9208* 1.4666 0.001 2.905 10.937 8 11.5636* 1.5222 0 7.475 15.652 6 4 -6.9208* 1.4666 0.001 -10.937 -2.905 8 4.6429* 0.8775 0 2.34 6.945 8 4 -11.5636* 1.5222 0 -15.652 -7.475 6 -4.6429* 0.8775 0 -6.945 -2.34 *. 均值差的显著性水平为 0.05。 Bonferroni和Tamhane多重比较的结果是一致的, cyl 的数量 4、6和8有显著区别。 Homogeneous Subsets mpg cyl N alpha = 0.05 的子集 1 2 3 Tukey Ba,b 8 14 15.1 6 7 19.743 4 11 26.664 将显示同类子集中的组均值。 a. 将使用调和均值样本大小 = 9.830。 b. 组大小不相等。将使用组大小的调和均值。将不保证 I 类错误级别。 Tukey B两两比较输出的结果，它把在5%的显著性水平下没有区别的总体放在同一列，作为同类子集。Cyl 数量为4，Cyl 数量为6，Cyl 数量为8有显著区别，各自单独分为一类 Means Plots 轮廓图为各个总体的均值的折线图，从中可以直观的看出各个总体均值的趋势。 回归分析一元线性回归模型（mpg~wt，前进法）Regression 输入／移去的变量a 模型 输入的变量 移去的变量 方法 1 wtb . 输入 a. 因变量: mpg b. 已输入所有请求的变量。 模型汇总b 模型 R R 方 调整 R 方 标准 估计的误差 1 .868a 0.753 0.745 3.0459 a. 预测变量: (常量), wt。 b. 因变量: mpg Anovaa 模型 平方和 df 均方 F Sig. 1 回归 847.725 1 847.725 91.375 .000b 残差 278.322 30 9.277 总计 1126.047 31 a. 因变量: mpg b. 预测变量: (常量), wt。 系数a 模型 非标准化系数 标准系数 t Sig. B 标准 误差 试用版 1 (常量) 37.285 1.878 19.858 0 wt -5.344 0.559 -0.868 -9.559 0 a. 因变量: mpg 残差统计量a 极小值 极大值 均值 标准 偏差 N 预测值 8.297 29.199 20.091 5.2293 32 残差 -4.5432 6.8727 0 2.9964 32 标准 预测值 -2.255 1.742 0 1 32 标准 残差 -1.492 2.256 0 0.984 32 a. 因变量: mpg 判定系数 R ̅^2 = 0.745，拟合优度较高，不被解释变量较少；对于常系数， sig.=0.00&lt;0.05，回归系数显著不为0；对于wt，sig.=0.00&lt;0.05，回归系数显著不为0；在方差分析表中，sig.=0.00&lt;0.01，回归模型非常显著回归方程为：mpg = -5.344*wt + 37.285 多元线性回归模型（mpg~disp+drat+wt+qsec，逐步回归）Regression 输入／移去的变量a 模型 输入的变量 移去的变量 方法 1 wt . 步进（准则: F-to-enter 的概率 &lt;= .050，F-to-remove 的概率 &gt;= .100）。 2 qsec . 步进（准则: F-to-enter 的概率 &lt;= .050，F-to-remove 的概率 &gt;= .100）。 a. 因变量: mpg 模型汇总c 模型 R R 方 调整 R 方 标准 估计的误差 1 .868a 0.753 0.745 3.0459 2 .909b 0.826 0.814 2.5962 a. 预测变量: (常量), wt。 b. 预测变量: (常量), wt, qsec。 c. 因变量: mpg Anovaa 模型 平方和 df 均方 F Sig. 1 回归 847.725 1 847.725 91.375 .000b 残差 278.322 30 9.277 总计 1126.047 31 2 回归 930.584 2 465.292 69.033 .000c 残差 195.464 29 6.74 总计 1126.047 31 a. 因变量: mpg b. 预测变量: (常量), wt。 c. 预测变量: (常量), wt, qsec。 系数a 模型 非标准化系数 标准系数 t Sig. B 标准 误差 试用版 1 (常量) 37.285 1.878 19.858 0 wt -5.344 0.559 -0.868 -9.559 0 2 (常量) 19.746 5.252 3.76 0.001 wt -5.048 0.484 -0.82 -10.43 0 qsec 0.929 0.265 0.275 3.506 0.001 a. 因变量: mpg 已排除的变量a 模型 Beta In t Sig. 偏相关 共线性统计量 容差 1 disp -.364b -1.929 0.064 -0.337 0.211 drat .128b 0.989 0.331 0.181 0.492 qsec .275b 3.506 0.001 0.546 0.969 2 disp -.003c -0.012 0.99 -0.002 0.131 drat .147c 1.35 0.188 0.247 0.491 a. 因变量: mpg b. 模型中的预测变量: (常量), wt。 c. 模型中的预测变量: (常量), wt, qsec。 残差统计量a 极小值 极大值 均值 标准 偏差 N 预测值 8.924 28.974 20.091 5.4789 32 残差 -4.3962 5.7486 0 2.511 32 标准 预测值 -2.038 1.621 0 1 32 标准 残差 -1.693 2.214 0 0.967 32 a. 因变量: mpg ss回归方程1：判定系数 R ̅^2 = 0.745，拟合优度较高，不被解释变量较少；对于常系数， sig.=0.00&lt;0.05，回归系数显著不为0；对于wt，sig.=0.00&lt;0.05，回归系数显著不为0；在方差分析表中，sig.=0.00&lt;0.01，回归模型非常显著回归方程为：mpg = -5.344wt + 37.285回归方程2：判定系数 R ̅^2 = 0.814，拟合优度较高，不被解释变量较少；对于常系数， sig.=0.01&lt;0.05，回归系数显著不为0；对于wt，sig.=0.00&lt;0.05，回归系数显著不为0；对于sqec，sig.=0.00&lt;0.05，回归系数显著不为0；在方差分析表中，sig.=0.00&lt;0.01，回归模型非常显著回归方程为：mpg = -5.048wt + 0.929*qsec + 19.746]]></content>
      <categories>
        <category>SPSS</category>
      </categories>
      <tags>
        <tag>SPSS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown基本语法]]></title>
    <url>%2F2018%2F09%2F02%2Fgganimate%EF%BC%9A%E6%9E%84%E5%BB%BAR%E8%AF%AD%E8%A8%80%E5%8F%AF%E8%A7%86%E5%8C%96gif%E5%8A%A8%E5%9B%BE-1%2F</url>
    <content type="text"><![CDATA[不定时更新……简书https://www.jianshu.com/p/191d1e21f7ed 制作表格 表头 表头 表头 内容 内容 内容 内容 内容 内容 第二行分割表头和内容。 -有一个就行，为了对齐，多加了几个文字默认居左-两边加：表示文字居中-右边加：表示文字居右 注：原生的语法两边都要用 | 包起来。此处省略 快速excel表格转换成markdown格式然后通过使用 exceltk0.0.4.7z 将excel文件转换为md文件 将exceltk0.0.4.7z压缩包解压，在dos下使用cd命令定位到它的解压路径下，1exceltk.exe -t md -xls xxx.xls 将xxx.xls改为你的excel文件的路径 最后它会生成一个md文件 doc 运行界面 原excel文件 exceltk.exe 转换后 md 文件 最终效果 换行在输入文字后面增加两个空格可以实现换行 居中1&lt;center&gt; ... &lt;/center&gt; 1234建议格式&lt;center&gt; ... &lt;/center&gt; … 添加在线视频通用代码1&lt;iframe height=498 width=510 src=&apos;http://music.163.com/m/mv?id=10770095&amp;userid=340573904&apos; frameborder=0 &apos;allowfullscreen&apos;&gt;&lt;/iframe&gt; 修改的src后的链接即可]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gganimate：构建R语言可视化gif动图]]></title>
    <url>%2F2018%2F09%2F02%2Fgganimate%EF%BC%9A%E6%9E%84%E5%BB%BAR%E8%AF%AD%E8%A8%80%E5%8F%AF%E8%A7%86%E5%8C%96gif%E5%8A%A8%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[gganimate简介gganimate是一款基于ggplot2的动态可视化扩展包，简单就是将ggplot2绘图对象转为gif动图的形式， 需要本地提前安装好ImageMagick这个软件，ImageMagick是一款功能强大且开源的图片处理和开发的软件包，安装的时候总是莫名其妙的报错，能不能一次性安装成功随缘。 下载安装1devtools::install_github("dgrtwo/gganimate") 绘图实例使用的是 gapminder的包中的全球主要国家在1952-2007年的GDP增长、人口变化以及预期寿命等方面的数据。现在我们想用 gganimate探索一下各大洲各主要国家GDP增长、预期寿命和人口增长是如何随时间变化的。123library(gapminder)library(ggplot2)theme_set(theme_bw()) 包下载太慢了，待更新…… 噗~ 包下载不成功详细步骤如下 ↓查看原文]]></content>
      <categories>
        <category>R</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>gganimate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Abela's folly]]></title>
    <url>%2F2018%2F08%2F21%2FAbela-s-folly%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>Others</category>
      </categories>
      <tags>
        <tag>未分类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Test]]></title>
    <url>%2F2018%2F08%2F09%2FUntitled%2F</url>
    <content type="text"><![CDATA[卧槽终于弄好了感谢大佬 ！！！！！！]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hello World ！]]></title>
    <url>%2F2018%2F08%2F09%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
